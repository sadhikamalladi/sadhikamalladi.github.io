<html>
<head>
    <title>Sadhika Malladi</title>
    <meta charset='UTF-8'>
    <meta content='width=device-width, initial-scale=1' name='viewport'/>

    <meta name='description' content='Sadhika Malladi is a PhD candidate at Princeton.'>
    <!-- A decent browser will parse this fine:
         https://webmasters.stackexchange.com/questions/92744. -->
    <meta name='keywords' content='
        machine learning,
        statistical machine learning,
        statistics,
        computational statistics,
        linear algebra,
        statistical software,
        deep learning,
        computer science
    '>
    <meta name='author' content='Sadhika Malladi'>
    <link href='https://sadhikamalladi.github.io/css/main.css' rel='stylesheet'/>

    <script type='text/x-mathjax-config'>
MathJax.Hub.Config({
  jax: ['input/TeX', 'output/HTML-CSS'],
  tex2jax: {
    inlineMath: [ ['$', '$'] ],
    displayMath: [ ['$$', '$$']],
    processEscapes: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
    extensions: ['color.js']
  },
  messageStyle: 'none',
  'HTML-CSS': { preferredFont: 'TeX', availableFonts: ['STIX','TeX'] }
});
</script>

<script src='//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS_HTML' type='text/javascript'></script>
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
</head>
<body>
  <div class='nav'>
    <ul class='wrap'>
        <li><a href='https://sadhikamalladi.github.io/index.html'>Home</a></li>
	<li><a href='https://sadhikamalladi.github.io/papers/index.html'>Papers</a></li>
	<li><a href='https://sadhikamalladi.github.io/service/index.html'>Teaching and Service</a></li>
	    <li><a href='https://sadhikamalladi.github.io/blog/index.html'>Research Blog</a></li>
        	<li><a href='https://sadhikamalladi.github.io/recruitment/index.html'>Student Recruitment</a></li>
    </ul>
</div>

  
  <div id='index' class='wrap'>
    <h1>Sadhika Malladi</h1>
    <img src="image/personal_photo.jpg" alt="Sadhika Malladi" class="personal-photo">

    <div id='about'>
      <p>I am currently a postdoctoral researcher at MSR NYC and will start as an Assistant Professor of Computer Science at UCSD in Fall 2026. I am actively recruiting students - please see my recruitment statement <a href="https://sadhikamalladi.github.io//recruitment/index.html">here</a>.</p>
      
    <p>I am wrapping up my PhD student in computer science at Princeton University, where I worked on theoretical machine learning with Sanjeev Arora. My work used mathematical insights into deep learning (especially language models) to design and analyze performant and efficient algorithms. I was recently named a 2025 Siebel Scholar. I graduated from MIT in 2019 with a degree in mathematics with computer science (18C) and a degree in philosophy (24-1). During my undergraduate studies, I also worked on language modeling at OpenAI in 2018 and 2019. </p><p>You can reach me at sadhika.malladi98@gmail.com.</p>
    
    <p>In my free time, I like to ride my bike, read, and watch sports. My Google scholar page is <a href="https://scholar.google.com/citations?hl=en&user=9HCmTcwAAAAJ">here</a>. I adapted this website from <a href="http://gregorygundersen.com" target="_blank">Gregory Gunderson</a>.</p>
  </div>

  <div id='research-areas' class='wrap'>
    <h2>Selected Works</h2>
    My work aims to advance ML theory, especially in optimization, to understand LLMs and design better algorithms to train them.

    <p><a href="https://arxiv.org/abs/2305.17333">Fine-Tuning Language Models with Just Forward Passes</a><br />
      <em><strong>Sadhika Malladi</strong>*, Tianyu Gao*, Eshaan Nichani, Alex Damian, Jason D. Lee, Danqi Chen,  Sanjeev Arora (Oral at NeurIPS 2023).</em> <br />
      We propose MeZO, a theoretically motivated memory-efficient zeroth-order optimizer to fine-tune LLMs, and we demonstrate that it can often effectively fine-tune models using up to 12x memory and half as many GPU-hours.
    </p>

    <p><a href="https://arxiv.org/abs/2210.05643">A Kernel-Based View of Language Model Fine-Tuning</a><br /> <em>               <strong>Sadhika Malladi</strong>, Alexander Wettig, Dingli Yu, Danqi Chen, Sanjeev Arora (ICLR 2021).</em> <br />
      We formally describe the optimization dynamics of language model fine-tuning as <em>kernel behavior</em> and verify this hypothesis through extensive experiments. Our theory provides insight into why parameter-efficient methods like LoRA work, and it motivated the development of MeZO.
    </p>

    <p><a href="https://arxiv.org/abs/2402.04333">LESS: Selecting Influential Data for Targeted Instruction Tuning</a><br />
      <em>Mengzhou Xia*, <strong>Sadhika Malladi</strong>*, Suchin Gururangan, Sanjeev Arora, Danqi Chen (ICML 2024).</em><br />
      We develop a model- and optimizer-aware data selection algorithm that permits using just 5% of the data to outperform using the entire dataset during instruction tuning.
    </p>

    <p>SDEs and scaling rules for <a href="https://arxiv.org/abs/2102.12470">SGD</a>, <a href="https://arxiv.org/abs/2307.15196">SGD with momentum</a>, <a href="https://arxiv.org/abs/2205.10287">RMSprop</a>, and <a href="https://arxiv.org/abs/2205.10287">Adam</a>.<br />
      <em>Different author lists, published at NeurIPS 2021, NeurIPS 2022, and ICLR 2024.</em><br />
      Our work with stochastic differential equations (SDEs) describes the optimization dynamics of training (nearly) arbitrary deep models from (nearly) arbitrary initialization on (nearly) arbitrary data using SGD, SGD with Momentum, RMSProp, and Adam. The theory lets us set hyperparameters to enable efficient learning in highly distributed settings (i.e., large batch size). My <a href="https://www.cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/">blog post</a> provides an accessible introduction to SDEs and the resulting practical implications for training vision and language models.</p>

    <p><a href="https://arxiv.org/abs/2405.19534">Preference Learning Algorithms Do Not Learn Preference Rankings</a><br />
      <em>Angelica Chen, <strong>Sadhika Malladi</strong>, Lily H. Zhang, Xinyi Chen, Qiuyi Zhang, Rajesh Ranganath, Kyunghyun Cho (NeurIPS 2024).</em><br />
      We demonstrate that preference learning algorithms rarely cause models to place higher likelihood on the preferred response over the dispreferred response.
    </p>
    <p><a href="https://arxiv.org/abs/2410.08847">Unintentional Unalignment: Likelihood Displacement in Direct Preference Optimization</a><br />
      <em>Noam Razin, <strong>Sadhika Malladi</strong>, Adithya Bhaskar, Danqi Chen, Sanjeev Arora, Boris Hanin (ICLR 2025).</em><br />
      Our theory and experiments demonstrate that standard preference learning methods can cause your language model to unalign, whereby it begins to answer harmful queries that it had previously refused. We propose a theory-motivated data filtering algorithm that effectively mitigates this unalignment.
    </p>
  </div>




</body>
</html>
