<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="cs.princeton.edu/~smalladi/feed.xml" rel="self" type="application/atom+xml" /><link href="cs.princeton.edu/~smalladi/" rel="alternate" type="text/html" /><updated>2025-10-24T11:38:58-07:00</updated><id>cs.princeton.edu/~smalladi/feed.xml</id><entry><title type="html">The Hidden Infinity in Preference Learning</title><link href="cs.princeton.edu/~smalladi/blog/2024/07/09/dpo-infinity/" rel="alternate" type="text/html" title="The Hidden Infinity in Preference Learning" /><published>2024-07-09T00:00:00-07:00</published><updated>2024-07-09T00:00:00-07:00</updated><id>cs.princeton.edu/~smalladi/blog/2024/07/09/dpo-infinity</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2024/07/09/dpo-infinity/"><![CDATA[<p><strong>TL;DR</strong>: I demonstrate from first principles how offline preference learning algorithms (e.g., <a href="https://arxiv.org/abs/2405.14734">SimPO</a>) can benefit from length normalization, especially when training on model-annotated preference data. The derivation also lends insight into a subtle but important challenge in training LMs: infinite strings.</p>

<hr />

<p>Aligning language models using human feedback has become increasingly popular. The process of collecting this feedback (i.e., a human rater reading and ranking pieces of text) is non-differentiable, so people turned to reinforcement learning (RL).</p>
<h1 id="learning-from-human-feedback-as-rl">Learning from Human Feedback as RL</h1>
<p>It turns out that it is confusing to translate the problem of improving language models via human feedback to the RL setting. First question: how should we define the states and the actions?</p>

<p>Originally, <a href="https://proceedings.mlr.press/v70/jaques17a.html">Jaques et al., 2017</a> designed the states in the problem to be the partial context, usually some combination of pre-filled prompt tokens and generated tokens, so the action was to pick a single token to generate next. I’ll refer to this as the <strong>token-level formulation</strong>. On the other hand, later works (<a href="https://arxiv.org/abs/1909.08593">Ziegler et al., 2019</a>; <a href="https://arxiv.org/abs/2009.01325">Stiennon et al., 2020</a>) framed the problem in a bandit setting, where the state is the pre-filled prompt and the action is to select which sequence to generate out of a few candidates. I’ll refer to this as the <strong>bandit formulation</strong>. Both of these designs are not perfectly suited to our setting, because we get human feedback on a sequence level but ask our LM to act on (i.e., generate) individual tokens. More recently, some works have designed objectives that incorporate token-level rewards or constraints alongside sequence-level feedback (<a href="https://arxiv.org/abs/2404.11999">Zeng et al., 2024</a>; <a href="https://arxiv.org/abs/2406.18629">Lai et al., 2024</a>). On the more theoretical and conceptual side, <a href="https://arxiv.org/abs/2404.12358">Rafailov et al., 2024</a> has a great illustration of this topic and draws meaningful connections between the two settings, and I’m sure that many RL papers are dedicated to parsing this gap between trajectory-level rewards and step-level actions.</p>

<p>The reason I bring up these two settings is to see how each one deals with the case of a model producing infinite-length strings. And yes, I know that it’s impossible in practice for LMs to actually generate an infinite-length string. But they can certainly put a tiny amount of probability mass on an infinite-length string. And if they do so for many such strings, then this ends up being a huge amount of probability mass lost to sequences that we’ll never see.</p>

<p>In the token-level formulation, it’s clear that an infinite-length string corresponds to essentially an infinite-length trajectory rolled out from the policy. One may think the bandit formulation somehow circumvents this problem because it provides only two bounded-length sequences for the model to choose from. But, when deriving optimal solutions to the bandit setting, you still need to deal with the problem of infinite “arms” (i.e., possible responses sampled from your policy). For example, Appendix A.1 of the <a href="https://arxiv.org/abs/2305.18290">DPO paper</a> glosses over the fact that the partition function $Z_\theta$ may not exist if you don’t bound the length of the generations or somehow assume that the reward decays with length. If you’re still not convinced that infinite-length strings matter, then stay tuned to see how this idea eventually plays out into a rigorous understanding of the role of length normalization.</p>

<h1 id="length-normalization">Length Normalization</h1>
<p>We can now derive how length normalization might make sense from the RL perspective. My disclaimer here is that I definitely worked backwards from the idea of length normalization to arrive at this justification, so there may be many other algorithms that are equally or better suited to operating in the setting I described. This derivation is also hand-wavy and meant more to provide intuition more than anything else. I’ll use the bandit-level formulation.</p>

<p>Suppose we have a prompt $x$ and two candidate completions $y_1$ and $y_2$. We will use $\Pr[y_1\succ y_2\mid x]$ to denote the proportion of people who prefer $y_1$ over $y_2$ as a completion to $x$.</p>

<p>The first thing we need to do is make some assumption about the reward structure. The Bradley-Terry (BT) model was derived to rigorously describe the distribution of human preferences:</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Pr</mi><mo>⁡</mo><mo stretchy="false">[</mo><msub><mi>y</mi><mn>1</mn></msub><mo>≻</mo><msub><mi>y</mi><mn>2</mn></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">]</mo><mo>=</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>r</mi><mtext>h</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>r</mi><mtext>h</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>+</mo><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>r</mi><mtext>h</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex"> \Pr[y_1\succ y_2\mid x] = \frac{\exp(r_\text{h}(x, y_1))}{\exp(r_\text{h}(x, y_1)) + \exp(r_\text{h}(x, y_2))}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mop">Pr</span><span class="mopen">[</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≻</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">exp</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">h</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>where $r_\text{h}(x,y)$ is the human ground-truth reward function that we don’t have access to. We already arrive at our first complication. In practice, some datasets are constructed by using an auxiliary model (e.g., GPT-4 or PairRM by <a href="https://aclanthology.org/2023.acl-long.792/">Jiang et al., 2023</a>) to pick which response is preferred. So, let’s call the reward function of such a language model $r_\text{LM}(x,y)$ and now consider the case where our data is annotated by a model (i.e., “RLAIF”).</p>

<p>One thing we do kind of know about $r_\text{LM}(x,y)$ is that it usually grows with the length of the response $y$. That is, models tend to favor longer responses. And in fact, one popular paper (<a href="https://arxiv.org/abs/2310.03716">Singhal et al., 2023</a>) showed that for some models, the reward grows <em>linearly</em> with the length of $y$. But in the case of alignment, it’s not clear if we always want our models to output longer sequences. For example, if we are trying to prevent harmful behavior, length is likely a spurious correlation. On the other hand, if we want to promote helpful behavior, increasing the length may somewhat correlate with providing useful information. Regardless, let’s disentangle length from the reward that we want to maximize and define $r^\star(x,y)$ such that</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>r</mi><mtext>LM</mtext></msub><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∣</mi><mi>y</mi><mi mathvariant="normal">∣</mi><msup><mi>r</mi><mo>⋆</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">r_\text{LM}(x,y) = |y| r^\star(x,y)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.32833099999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord text mtight"><span class="mord mtight">LM</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span></span></span></span></span></p>

<p>Now, we want to learn a model $\pi^\star$ that is trained with access to only data annotated according to $r_\text{GPT}$ but maximizes the length-normalized reward $r^\star$. In other words, we can write:</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>r</mi><mo>⋆</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><msup><mi>π</mi><mo>⋆</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∣</mi><mi>y</mi><mi mathvariant="normal">∣</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex"> r^\star(x,y) = \frac{\log(\pi^\star(x,y))}{|y|} </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.363em;vertical-align:-0.936em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.688696em;"><span style="top:-3.063em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="mclose">)</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p>

<p>where I’m keeping with the standard ML practice of considering the log-likelihood of a softmax-parametrized model instead of the likelihood directly. We can now define a score $\Lambda$ using $r^\star$.</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Λ</mi><mo stretchy="false">[</mo><msub><mi>y</mi><mn>1</mn></msub><mo>≻</mo><msub><mi>y</mi><mn>2</mn></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">]</mo><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msup><mi>r</mi><mo>⋆</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>−</mo><msup><mi>r</mi><mo>⋆</mo></msup><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex"> \Lambda[y_1\succ y_2 \mid x] = \sigma(r^\star(x,y_1) - r^\star(x,y_2)) </annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">Λ</span><span class="mopen">[</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≻</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault">x</span><span class="mclose">]</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">r</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.738696em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mbin mtight">⋆</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.30110799999999993em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>

<p>where $\sigma$ is the sigmoid function. Note that the DPO derivation does not rely on pulling this score out of thin air because they used the Bradley-Terry assumption on $r_\text{h}$ to show that, if the data is human-annotated, then $\sigma(r_\text{h}(x, y_1) - r_\text{h}(x, y_2))$ is exactly equal to the ground-truth probability that $y_1$ is preferred over $y_2$. Here, however, I want to make it clear that we have no reason to believe that $r^\star$ obeys the Bradley-Terry assumption. But, optimistically, if it did, then $\Lambda$ would define a valid probability distribution capturing how much the <em>model</em> prefers $y_1$ over $y_2$ if we removed the bias that favored long responses.</p>

<p>Now, we want to train the model to maximize this score in the case that $y_1 = y_w$ is the winning response and $y_2=y_l$ is the losing one. So we can write our length-normalized objective as</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">(</mo><msub><mi>π</mi><mi>θ</mi></msub><mo separator="true">,</mo><mi mathvariant="script">D</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mo><mi mathvariant="double-struck">E</mi></mo><mrow><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><msub><mi>y</mi><mi>w</mi></msub><mo separator="true">,</mo><msub><mi>y</mi><mi>l</mi></msub><mo stretchy="false">)</mo><mo>∼</mo><mi mathvariant="script">D</mi></mrow></msub><mrow><mo fence="true">[</mo><mi>log</mi><mo>⁡</mo><mi>σ</mi><mrow><mo fence="true">(</mo><mfrac><mrow><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>w</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mi>w</mi></msub><mi mathvariant="normal">∣</mi></mrow></mfrac><mo>−</mo><mfrac><mrow><mi>log</mi><mo>⁡</mo><msub><mi>π</mi><mi>θ</mi></msub><mo stretchy="false">(</mo><msub><mi>y</mi><mi>l</mi></msub><mo>∣</mo><mi>x</mi><mo stretchy="false">)</mo></mrow><mrow><mi mathvariant="normal">∣</mi><msub><mi>y</mi><mi>l</mi></msub><mi mathvariant="normal">∣</mi></mrow></mfrac><mo fence="true">)</mo></mrow><mo fence="true">]</mo></mrow></mrow><annotation encoding="application/x-tex"> \mathcal{L}(\pi_\theta, \mathcal{D}) = \mathop{\mathbb{E}}_{(x, y_w, y_l)\sim\mathcal{D}} \left[\log \sigma \left(\frac{\log \pi_\theta (y_w\mid x)}{|y_w|} - \frac{\log \pi_\theta(y_l\mid x)}{|y_l|}\right)\right]</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathcal">L</span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.40003em;vertical-align:-0.95003em;"></span><span class="mop"><span class="mop"><span class="mord"><span class="mord mathbb">E</span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.34480000000000005em;"><span style="top:-2.5198em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">x</span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.16454285714285719em;"><span style="top:-2.357em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em;"><span></span></span></span></span></span></span><span class="mpunct mtight">,</span><span class="mord mtight"><span class="mord mathdefault mtight" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3448em;"><span style="top:-2.3487714285714287em;margin-left:-0.03588em;margin-right:0.07142857142857144em;"><span class="pstrut" style="height:2.5em;"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15122857142857138em;"><span></span></span></span></span></span></span><span class="mclose mtight">)</span><span class="mrel mtight">∼</span><span class="mord mtight"><span class="mord mathcal mtight" style="margin-right:0.02778em;">D</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.3551999999999999em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">[</span></span><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.03588em;">σ</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="minner"><span class="mopen delimcenter" style="top:0em;"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.151392em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02691em;">w</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.427em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">∣</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mord">∣</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mop">lo<span style="margin-right:0.01389em;">g</span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">π</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.02778em;">θ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.33610799999999996em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.01968em;">l</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">∣</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mord mathdefault">x</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">)</span></span></span><span class="mclose delimcenter" style="top:0em;"><span class="delimsizing size3">]</span></span></span></span></span></span></span></p>

<p>And so we arrive at a length-normalized preference learning objective. There are some interesting takeaways from this derivation.</p>
<ol>
  <li>If we’re going to annotate preference data using other models, then we can actually adjust our objectives to counteract known biases in the scoring. Length normalization is one example of this strategy. If and when other ones come to light, we could feasibly use this approach to allow our models to learn from imperfectly annotated data. We can analogously use this approach to correct biases in human-annotated data as well, though we ought to exercise a lot more caution and thought when shifting or otherwise modifying human-expressed preferences.</li>
  <li>Note that no matter what I do, this current strategy cannot link $r_{\text{LM}}$ to $r_\text{h}$ – that is, I can’t really describe how the rewards that the model provides relate to the ground-truth human rewards. Instead, all I can say is that length-normalized objectives provide one possible strategy for mitigating the absorption of biases from the models used to annotate the data. By the same token, it doesn’t matter if the annotator LM was trained on human data or not. These nuances are something I hope to explore in future work!</li>
  <li>Connection to <strong>average reward maximization</strong>: Another way to see $r^\star(x,y)$ is that it’s the average reward of each token in the sequence. This links length normalization to a long line of RL algorithms that maximize the average reward instead of the total reward (see a survey in <a href="https://link.springer.com/article/10.1007/BF00114727">Mahadevan, 1996</a>). This formulation is especially useful when dealing with cyclical or infinite-horizon problems. Note that another way to deal with infinite-horizon problems is to discount rewards that will arrive in the future – if you were to do this, then you would arrive at the length-regularized DPO objective (<a href="https://arxiv.org/abs/2403.19159">Park et al., 2024</a>).</li>
  <li>If we just look at the final length-normalized objective, then we can see that it explicitly requires $\pi_\theta(y_w\mid x)$ to increase much more than it would if there was no normalization. Other modifications to the objective, like target reward margins, do not <em>explicitly</em> ensure that this will happen, because they operate on the distance between the two likelihoods. After all is said and done, we usually just use $\pi_\theta$ to generate sequences, so directly modifying it seems like it would be more effective.</li>
</ol>

<h1 id="discussion">Discussion</h1>
<p>The derivation above demonstrates how we might adjust our objective functions to enable learning from imperfectly (e.g., automatically) annotated data. I think that using other models to grade or annotate preference data will become increasingly prevalent, due to growing evidence that preference learning with on-policy data is more effective (<a href="https://arxiv.org/abs/2404.14367">Tajwar et al., 2024</a>) and the rising cost of finding and hiring qualified human annotators. In this post, I considered the case where the preference data was model-annotated and the model had a bias favoring longer responses. The analysis provides some insight into one particular situation in which length normalization makes sense, but it by no means provides a general prescriptive guideline for objective design.</p>

<p>I was originally motivated to derive this after reading about SimPO (<a href="https://arxiv.org/abs/2405.14734">Meng et al., 2024</a>), which proposes a length-normalized preference learning objective. If you are curious about the other modifications in SimPO – removing the reference model and setting a global target reward margin – then you might be interested in reading <a href="https://arxiv.org/abs/2405.19534">our recent paper</a> on how the reference model can prevent DPO from aligning effectively.</p>

<p>The possibility of infinite-length strings has been explored in several prior works, mainly with a focus on characterizing how prone a particular model architecture (e.g., transformer or RNN) is to leaking probability mass to infinite-length strings and how certain objectives might exacerbate or mitigate this issue (<a href="https://aclanthology.org/2020.emnlp-main.448/">Welleck et al., 2020</a>; <a href="https://aclanthology.org/2023.acl-long.543/">Du et al., 2023</a>).</p>

<p>There is also a big leap missing from what I have derived so far. We may train a policy $\pi^\star$ to maximize rewards but when we sample from the model (e.g., via greedy decoding), we don’t actually obtain a sequence that maximizes the log likelihood prescribed by the model. This was, after all, the motivation for developing many different decoding strategies, including ones that implicitly plan or search. In the context of post-training, I find this observation fascinating, given how the field has primarily focused on next-token prediction objectives as a means to constrain or guide long-form generations.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> Some of my research going forward will be on this topic of the gap between next-token prediction and long-form generation. If you are interested in this direction, I enjoyed reading several of <a href="https://cimeister.github.io/publication/">Clara Meister’s papers</a>.</p>

<p>Since this is a blog post and not a paper, I’m not doing a full literature survey on these topics. As I mentioned, there are many RL papers on these topics, and my main research area is not RL. That being said, if I didn’t mention your paper and you think it is relevant, kindly send me an email!</p>

<p><strong>Acknowledgments</strong>: Thank you (in alphabetical order) to Angelica Chen, Xinyi Chen, Yu Meng, and Mengzhou Xia for discussions that helped me refine my derivation and for suggesting several relevant papers. And also thank you to Adithya Bhaskar, Tianyu Gao, Lucy He, and Kaifeng Lyu for helping me proofread this post. Thanks also to Ben Eysenbach for pointing me in the direction of average reward maximization.</p>

<p><strong>Citation</strong>: If you find this blog post to be helpful in your work, please use the following bibtex citation.</p>
<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>@misc{malladi2024hiddeninfinity,
  title   = {The Hidden Infinity in Preference Learning},
  author  = {Malladi, Sadhika},
  year    = {2024},
  month   = {July},
  url     = {https://www.cs.princeton.edu/~smalladi/blog/2024/06/27/dpo-infinity/},
}
</code></pre></div></div>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>OK, to be fair, there are papers that now train models to predict several tokens into the future (<a href="https://arxiv.org/abs/2404.19737">Gloeckle et al., 2024</a>), but I would argue this is just a patch over the underlying problem. Similarly, there are papers that allow a model to access and train on its own generations (e.g., STaR, <a href="https://arxiv.org/abs/2203.14465">Zelikman et al., 2022</a>), but I’m not fully convinced that this closes the gap between training and inference. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>Sadhika Malladi</name></author><summary type="html"><![CDATA[TL;DR: I demonstrate from first principles how offline preference learning algorithms (e.g., SimPO) can benefit from length normalization, especially when training on model-annotated preference data. The derivation also lends insight into a subtle but important challenge in training LMs: infinite strings.]]></summary></entry><entry><title type="html">Using LESS Data to Tune Models</title><link href="cs.princeton.edu/~smalladi/blog/2024/04/04/dataselection/" rel="alternate" type="text/html" title="Using LESS Data to Tune Models" /><published>2024-04-04T00:00:00-07:00</published><updated>2024-04-04T00:00:00-07:00</updated><id>cs.princeton.edu/~smalladi/blog/2024/04/04/dataselection</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2024/04/04/dataselection/"><![CDATA[<p><strong>TL;DR</strong>: We describe how data selection for modern-day LLMs differs from prior settings and how our algorithm, <strong>LESS</strong>, effectively selects relevant data to cultivate specific capabilities in models during instruction tuning.</p>

<p><strong>Paper:</strong> <a href="https://arxiv.org/abs/2402.04333">https://arxiv.org/abs/2402.04333</a></p>

<p><strong>Code:</strong> <a href="https://github.com/princeton-nlp/LESS/tree/main">https://github.com/princeton-nlp/LESS/</a></p>

<hr />

<p>This post will take the following structure:</p>

<ul>
  <li>We introduce the motivation for data selection and describe how the criteria for “good” data depends heavily on the <a href="#motivation">setting</a>. One can either try to identify <strong>representative</strong> datapoints for the in-domain setting or <strong>relevant</strong> ones for the transfer setting.</li>
  <li>Our algorithm, <a href="#less">LESS</a>, effectively selects relevant data to induce capabilities in the instruction tuning setting. LESS identifies 5% of the dataset that induces stronger performance than training on the full dataset.</li>
  <li>We conduct an <a href="#prior-work">in-depth analysis of prior works</a> on data selection for various settings and provide insights into their technical details, strengths, and limitations.</li>
  <li>We conclude by identifying trends in data selection in the era of LLMs.</li>
</ul>

<hr />

<h1 id="motivation">Motivation</h1>

<p>The training dataset is a crucial design choice when building a machine learning model. Dataset choice can drive the <strong>capabilities</strong> of the resulting model in various ways (see, for example, <a href="https://arxiv.org/abs/2308.12950">CodeLLaMA</a>, and <a href="https://arxiv.org/abs/2402.03300">DeepSeek-Math</a>). Also, training models can be expensive, and the cost usually scales with the size of the dataset, so dataset selection offers one way to improve <strong>efficiency</strong> and reduce cost<strong>.</strong></p>

<center>
<div class="figure">
<img src="/~smalladi/assets/dataselection_img/settings.svg" alt="Cartoon of coreset selection vs transfer data selection." style="
 margin-left: auto;
 margin-right: auto;
 width: 95%;" />
 <br />
 
 <div class="caption">
 <span class="caption-label"><i>Coreset selection</i> selects data such that the selected subset represents the full dataset. 
<br /><i>Transfer data selection</i> selects the subset that is closest to the target data points. </span>
</div></div></center>

<p>We distinguish two settings for data selection: in-domain data selection and transfer data selection. In the former, the selected data is drawn from the same distribution as the evaluation data<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> , whereas in the latter, evaluation is performed on different data.</p>

<ul>
  <li><em>In-domain data selection</em> aims to identify the most <strong>representative</strong> subset of data, often referred to as a coreset (<a href="https://arxiv.org/abs/1708.00489">Sener &amp; Severese 2018</a>), from a large in-domain training dataset. The selection criteria include representativeness, coverage, correctness, and more. We talk more about this setting latter.</li>
  <li><em>Transfer data selection</em> seeks to choose the most <strong>relevant</strong> data from a broad training pool that closely align with the target examples. The selection criterion focuses on relevancy.</li>
</ul>

<p>Our work focuses on <strong>transfer data selection for</strong> <strong>instruction tuning</strong>. Instruction tuning has proven to be a highly effective way to quickly adapt language models to follow human instructions. Depending on the data used, models can be tuned to be general-purpose instruction followers (e.g., <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html">Alpaca</a>, <a href="https://lmsys.org/blog/2023-03-30-vicuna/">Vicuna</a>, <a href="https://arxiv.org/abs/2310.16944">Zephyr</a>) or solve more structured tasks per human instructions (i.e., <strong>targeted instruction tuning</strong>). Our work focuses on selecting data for the latter case, where models are tuned to perform particular types of reasoning (e.g., using a passage to answer a question). In this case, the data selection problem can be understood as bootstrapping a few examples to identify relevant data to solve a task.</p>

<h1 id="less">Selecting LESS Datapoints for Targeted Instruction Tuning</h1>

<p>The targeted instruction tuning setting poses the following research question:</p>

<center>
<i>Given just a few handwritten examples of a query type and a particular pre-trained model, how can we identify the most relevant data to train on out of a large pool of available instruction tuning data?</i>
</center>

<p>Several data selection strategies have been developed for pre-training, such as continued training on domain-specific data (<a href="https://arxiv.org/abs/2004.10964">Gururangan et al., 2020</a>) and using n-gram statistics to identify relevant data (<a href="https://arxiv.org/abs/2302.03169">Xie et al., 2023</a>). However, the instruction tuning setting is unique in that using all of the available data can hurt the development of specific capabilities (<a href="https://arxiv.org/abs/2306.04751">Wang et al., 2023</a>), and one wants to somehow account for the properties of the pre-trained model when selecting data. So, we avoid using heuristic definitions of useful data and instead frame data selection as a rigorous optimization problem. As we describe in the next section, LESS selects training data to minimize the loss on the target data (i.e., the few handwritten validation examples).
Check out our paper <a href="https://arxiv.org/abs/2402.04333" target="_blank">here</a> and play with the code on <a href="https://github.com/princeton-nlp/LESS" target="_blank">GitHub</a>!</p>

<h2 id="conceptual-approach">Conceptual Approach</h2>

<p>Suppose we have a handwritten validation example $z$ and a huge dataset of candidate training points $\mathcal{D}$. At the heart of any transfer data selection algorithm is the same question: how does training on some point $x\in\mathcal{D}$ affect the model’s performance on $z$? We explicitly formulate this by approximating how the validation loss $\ell(z;\theta)$ changes when we take one training step (i.e., update the model from $\theta_t$ to $\theta_{t+1}$) on a candidate datapoint $x$:</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>≈</mo><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mo stretchy="false">⟨</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo>−</mo><msub><mi>θ</mi><mi>t</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">
\ell(z;\theta_{t+1}) \approx \ell(z;\theta_t) + \langle \nabla \ell (z;\theta_t), \theta_{t+1} - \theta_t \rangle
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mopen">⟨</span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">⟩</span></span></span></span></span></p>

<p>Assume that we were training with SGD with step size $\eta_t$, we can further derive the following formulation:</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msub><mo stretchy="false">)</mo><mo>−</mo><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>≈</mo><msub><mi>η</mi><mi>t</mi></msub><mo stretchy="false">⟨</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">
\ell(z;\theta_{t+1}) -\ell(z;\theta_t) \approx \eta_t\langle \nabla \ell (z;\theta_t), \nabla \ell (x;\theta_t)\rangle
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.301108em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">t</span><span class="mbin mtight">+</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.208331em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">≈</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.03588em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mopen">⟨</span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">⟩</span></span></span></span></span></p>

<p>We can see that selecting $x$ to maximize $\langle \nabla \ell (z;\theta_t), \nabla \ell (x;\theta_t)\rangle$ will maximally reduce the validation loss on $z$. The method was initially proposed and employed in TracIn (<a href="https://arxiv.org/abs/2002.08484">Pruthi et al., 2020</a>) to gain insights into how training examples influence the model’s predictions. The formulation is also very suitable for transfer learning, because there is no need to assume any relationship between $x$ and $z$. But, there are a couple of modifications required to make it work for our setting (see  <a href="https://arxiv.org/abs/2402.04333" target="_blank">our paper</a> for details):</p>

<ol>
  <li><strong>Adam:</strong> LLMs are generally tuned using Adam, which has a more complicated update formula involving the moving averages of the gradient moments. We can plug in that update, which we denote as $\Gamma(x;\theta_t)$ instead of $\nabla\ell(x;\theta_t)$. See the paper for details on the Adam formulation and the resulting technical complications.</li>
  <li><strong>Multi-Epoch:</strong> We usually train our models over several epochs, which means each candidate $x\in\mathcal{D}$ would be seen several times over the course of training. We would want our estimate of the influence of $x$ to take this into account, but we want to avoid the computational cost of training on the entire candidate dataset for several epochs. Instead, we approximate how the model would adapt to seeing the same data by performing a warmup training period on a randomly selected 5% of the data and aggregating the influence over the whole run. See the paper for how we aggregate influences over multiple epochs.</li>
  <li><strong>Variable-Length Instruction Data</strong>: Instruction tuning sequences have differing lengths. Experiments in our paper showed that shorter sequences exhibit much larger norms, so the inner product $\langle \nabla \ell (z;\theta_t), \nabla \ell (x;\theta_t)\rangle$ is much larger for shorter $x$. We therefore decide to instead use the cosine similarity instead of the inner product when measuring the influence. This is not a failure of the formulation described above (which indeed is quite simple); instead, it indicates that we ought to perform data selection for <em>individual tokens</em> instead of <em>entire sequences</em>. However, measuring the gradient of every token in the sequence is prohibitively expensive with today’s methods, so we stick to sequence selection and leave a token-level formulation to future work.</li>
</ol>

<p>Altogether, once we make the necessary modifications, we arrive at the following formula for computing the influence of a training datapoint $x$ on a validation point $z$.</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Influence</mtext><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">,</mo><mi>z</mi><mo stretchy="false">)</mo><mo>=</mo><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mover accent="true"><mi>η</mi><mo>ˉ</mo></mover><mi>i</mi></msub><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi>z</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi mathvariant="normal">Γ</mi><mo stretchy="false">(</mo><mi>x</mi><mo separator="true">;</mo><msub><mi>θ</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\textrm{Influence}(x, z) = \sum_{i=1}^N \bar{\eta}_i \cos (\nabla \ell(z;\theta_i), \Gamma(x; \theta_i))
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord text"><span class="mord textrm">Influence</span></span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.10903em;">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord accent"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.56778em;"><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.03588em;">η</span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="accent-body" style="left:-0.19444em;"><span class="mord">ˉ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.19444em;"><span></span></span></span></span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop">cos</span><span class="mopen">(</span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord">Γ</span><span class="mopen">(</span><span class="mord mathdefault">x</span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.02778em;">θ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.02778em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose">)</span></span></span></span></span></p>

<p>where $\Gamma(x; \theta_i)$ is the Adam update mentioned above, $N$ is the number of epochs during warmup training (see next section), $\bar\eta_i$ is the average learning rate in the $i$th epoch, and $\theta_i$ is the model after the $i$th epoch. The above formula makes it clear that we need to handle model gradient vectors, which can be very large, and we need to aggregate influences over several model checkpoints. In the next section, we describe how we compute this formula efficiently.</p>

<h2 id="selecting-less-data">Selecting LESS Data</h2>

<center>
<img src="/~smalladi/assets/dataselection_img/method2-cropped.svg" alt="The four major steps of LESS" style="
 margin-left: auto;
 margin-right: auto;
 width: 80%;" />
 <br /><br /><br />
 <div class="caption">
 <span class="caption-label">An overview of the four steps of our algorithm, <a href="https://arxiv.org/abs/2402.04333" target="_blank">LESS</a>. </span>
</div></center>

<p><strong>LESS</strong> consists of four major steps to make influence estimation feasible and scalable:</p>

<ol>
  <li><strong>Warmup LoRA training:</strong>  We train the model with a warmup phase with a random subset of data and checkpoint the model $\theta_i$ and optimizer update $\Gamma$ over $N$ epochs. We choose to train with LoRA to operate on gradients in a much smaller space (i.e., ~100M parameters for a 7B model).</li>
  <li><strong>Compute gradient features:</strong> We acquire low-rank <strong>Adam</strong> gradients by further projecting the LoRA gradients down to a smaller dimension $d$ (i.e., 8192 in our experiments).<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup></li>
  <li><strong>Select data:</strong> Given a few instances from target tasks, we first acquire their compressed gradients. We then calculate the influence $\mathrm{Inf}$ and pick the examples with the highest scores.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup></li>
  <li><strong>Train models:</strong> We train models on the selected data, using either full-parameter fine-tuning or efficient fine-tuning approaches like LoRA.</li>
</ol>

<p>Note that the first and second steps are computed once per candidate training set and can be stored as a <strong>gradient datastore</strong>. The datastore can be reused to quickly select data for different validation tasks. Moreover, the model used to select data in steps 1-3 can be different from the model trained in step 4, and we call this setting LESS-T, where “T” stands for transfer.</p>

<h2 id="results">Results</h2>

<p><strong>Training on 5% selected data often outperforms training on the full dataset</strong></p>

<p>We construct our dataset pool to be a combination of subsets <a href="https://huggingface.co/datasets/SirNeural/flan_v2">FLAN V2</a>, COT, <a href="https://huggingface.co/datasets/OpenAssistant/oasst1">Open Assistant 1</a>, and <a href="https://www.notion.so/Using-LESS-data-to-tune-models-data-selection-in-the-era-of-LLMs-f85c2d946baa45afa974b5f021200b38?pvs=21">Dolly</a> datasets. On Mistral-7B and Llama-2-13B, we find that the selected 5% of the data outperforms using the full dataset. Additionally, we find that the data selected with Llama-2-7B is also effective for instruction-tuning Llama-2-13B and Mistral-7B (LESS-T).</p>

<center>
<div class="figure">
<img src="/~smalladi/assets/dataselection_img/llama_bar.svg" alt="Bar chart of results" style="
 margin-left: auto;
 margin-right: auto;
 width: 48%;" />
 <img src="/~smalladi/assets/dataselection_img/mistral_bar.svg" alt="Bar chart of results" style="
 margin-left: auto;
 margin-right: auto;
 width: 48%;" />
 <br />
 
 <div class="caption">
 <span class="caption-label">Training on just 5% of the data, selected by our algorithm <a href="https://arxiv.org/abs/2402.04333" target="_blank">LESS</a>, outperforms training on the full dataset. </span>
</div></div></center>

<center>
<div class="figure">
<img src="/~smalladi/assets/dataselection_img/table.png" alt="Table of results" style="
 margin-left: auto;
 margin-right: auto;
 width: 100%;" />
 <br />
 
 <div class="caption">
 <span class="caption-label">In-depth results of using <a href="https://arxiv.org/abs/2402.04333" target="_blank">LESS</a> on three benchmarks.</span> <br />LESS-T indicates that we used LLaMA-2-7B to select the data for training the model.
</div></div></center>

<p><strong>LESS outperforms the baselines</strong></p>

<p>We compare our approach to several baselines with different <strong>relevancy</strong> criteria.</p>

<ul>
  <li>Random: random selection</li>
  <li>BM25: computes lexical overlap as a relevancy score and selects the examples with the highest scores</li>
  <li>DSIR (Xie et al., 2023): weight candidate training data with n-gram features, and resample data based on the weights</li>
  <li>RDS: uses model’s hidden representations as features and selects the examples with the highest similarity scores</li>
</ul>

<p>We surprisingly find that LESS is the only approach that consistently outperforms random selection. Other approaches, unfortunately, either provide minimal improvement over random selection (BM25), or underperform random selection. In the next section, we provide qualitative examples to have an in-depth understanding of why other approaches fail.</p>

<center>
<div class="figure">
<img src="/~smalladi/assets/dataselection_img/baselines.jpeg" alt="LESS outperforms baselines (bar chart)" style="
 margin-left: auto;
 margin-right: auto;
 width: 60%;" />
 <br />
 
 <div class="caption">
 <span class="caption-label">LESS outperforms all baselines.</span>
</div></div></center>

<p><strong>LESS selects examples with similar underlying task structures</strong></p>

<p>We provide top selected examples by BM25, RDS and LESS for a TydiQA example. The TydiQA example presents a paragraph and a question in Bengali, and the goal is to locate an answer to the question within the given paragraph. BM25 and RDS select examples in Bengali, but these examples are related to a different task. In contrast, LESS selects a question-answering example written in English, which is more relevant to the target task.</p>

<p>This pattern holds true for the top examples selected for other questions. Upon further investigation, we discovered that the top examples selected by BM25 and RDS are predominantly in Bengali, whereas LESS consistently chooses examples in English that are specifically related to question answering. This observation suggests that LESS prioritizes examples that share a similar reasoning process, while the other approaches place too much emphasis on superficial cues such as language or topic, rather than the underlying task structure.</p>

<center>
<div class="figure">
<img src="/~smalladi/assets/dataselection_img/qualitative.png" alt="Qualitative analysis of examples chosen by LESS." style="
 margin-left: auto;
 margin-right: auto;
 width: 100%;" />
 <br />
 
 <div class="caption">
 <span class="caption-label">Qualitative analysis of selected data.</span> <br /> LESS circumvents surface-form cues to instead select examples with similar reasoning types as the validation data.
</div></div></center>

<p><strong>More computation on data selection enhances performance</strong></p>

<p>Our ablations in the  <a href="https://arxiv.org/abs/2402.04333" target="_blank">paper</a> show that spending more computation in any of the steps of LESS can improve the performance of the method at the cost of additional runtime. For example, using a longer warmup phase in step 1, increasing the projected dimension in step 2, and aggregating the influence estimate over more model checkpoints can all improve performance at the cost of runtime and/or memory. We report results in a setting where the data selection cost is reasonable: selecting and training on the data requires less time than training on all available data. However, our results show that training on LESS data can even <strong>improve</strong> performance, so it may be worthwhile to invest more resources into the selection stage.</p>

<h1 id="prior-work">Past Works on Data Selection</h1>

<p>In this section, we discuss many related works in-domain data selection and transfer data selection.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" class="footnote" rel="footnote">4</a></sup> Our goal is to briefly cover the many broad intuitions that can inform different data selection algorithms.</p>

<h2 id="in-domain-data-selection">In-Domain Data Selection</h2>

<p>As we mentioned before, the goal of data selection depends heavily on the setting. When ample labeled in-domain data is available (e.g., image classification in vision is an obvious case, pre-training data selection is also one), the goal is to identify the most <strong>representative</strong> subset of data, so much of the past work has sought to define the notion of “representative” datapoints. <a href="https://arxiv.org/abs/1708.00489">Sener &amp; Severese 2018</a> explicitly defines this problem to be a core-set problem (<a href="https://arxiv.org/abs/1703.06476">Bachem et al., 2017</a>, <a href="https://www.jmlr.org/papers/v20/18-167.html">Tremblay et al., 2019</a>), which aims to choose a set of datapoints such that each data point is close to at least one selected data point. Subsequent research has linked specific attributes of datapoints, such as being “easy to forget” (<a href="https://arxiv.org/abs/1812.05159">Toneva et al., 2019</a>), exhibiting “large prediction error” (<a href="https://arxiv.org/abs/2107.07075">Paul et al., 2021</a>), being “hard to memorize” (<a href="https://arxiv.org/pdf/2008.03703.pdf">Feldman et al., 2020</a>), being “redundant in clustering” (<a href="https://arxiv.org/abs/1901.11409">Birodkar et al., 2019</a>) and having “uncertain predictions” (<a href="https://arxiv.org/abs/1905.12737">Chitta et al., 2019</a>) with their representativeness and importance. <a href="https://arxiv.org/abs/2206.14486">Sorscher et al., 2022</a> consolidate these attributes under the category of hard examples, proposing that these instances are the most critical for effective training. One can also use gradient-based features (<a href="https://arxiv.org/abs/1906.01827">Mirzasoleiman et al., 2020</a>, <a href="https://proceedings.mlr.press/v119/wang20p.html">Wang et al., 2020</a>, <a href="https://arxiv.org/abs/2103.00123">Killamsetty et al., 2021</a>) for data selection. This naturally lends itself to a more general meta-learning formulation, which we discuss more below.</p>

<h3 id="pre-training">Pre-Training</h3>

<p>In recent years, the pre-training and fine-tuning paradigm has proven to be an effective way to build large-scale foundation models. Unlike models trained with curated task-specific datasets like CIFAR or ImageNet, these models are trained with massive Internet-scraped data consisting of trillions of tokens or images. These two settings differ in two ways: (1) quality: web-scale datasets are generally heterogeneous in quality; and (2) scale: data selection has strong implications on efficiency in the foundational model era. We consider general pre-training data selection to be a form of in-domain data selection, as it aims to choose data that covers all potential use cases.</p>

<p><strong>Algorithmic Filtering:</strong> Early in 2019, researchers have found that excluding high-perplexity examples from CommonCrawl could significantly boost training efficiency, since such examples are often nonsensical or of low quality (<a href="https://arxiv.org/abs/1911.00359">Wenzek et al., 2019</a>, <a href="https://arxiv.org/abs/2309.04564">Marion et al., 2023</a>). More sophisticated processing identified high-quality data by filtering domains and URLs, ensuring diversity, and removing redundancy (e.g., via <a href="https://www.notion.so/Using-LESS-data-to-tune-models-data-selection-in-the-era-of-LLMs-f85c2d946baa45afa974b5f021200b38?pvs=21">MinHashLSH</a> or semantic deduplication (<a href="https://arxiv.org/abs/2303.09540">Abbas et al., 2023</a>)). Many popular datasets were constructed in this way, including C4 (<a href="https://arxiv.org/abs/1910.10683">Raffel et al., 2021</a>), RefinedWeb (<a href="https://arxiv.org/abs/2306.01116">Penedo et al., 2023</a>), SlimPajama (<a href="https://arxiv.org/abs/2309.10818">Shen et al., 2023</a>), and more. Similar efforts have been explored for pre-training VIT models (<a href="https://arxiv.org/abs/2401.04578">Abbas et al., 2024</a>).</p>

<p><strong>LLM-Aided Filtering</strong>: An extreme form of algorithmic filtering is to explicitly prompt LLMs to generate data satisfying certain properties. The approach’s efficacy is clearest in the Phi-series models (<a href="https://arxiv.org/abs/2306.11644">Gunasekar et al., 2023</a>, <a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Javaheripi et al., 2024</a>), which achieved strong performance on math and coding benchmarks with only 1.3B model parameters. While the Phi-series models focus on generating textbook-style data, other recent work has shown that rephrasing pre-training data to mimic the stylistic and informational density of Wikipedia articles markedly enhances the data’s cost-effectiveness (<a href="https://arxiv.org/abs/2401.16380">Maini et al., 2024</a>). Aside from generating data, LLMs can also be used to judge the quality of data. Recent works such as QuRating (<a href="https://arxiv.org/abs/2402.09739">Wettig et al., 2024</a>) and Ask-LLM (<a href="https://arxiv.org/abs/2402.09668">Sachdeva et al., 2024</a>)  aim to exploit capable language models to directly provide quality scores to data instances, offering a metric for evaluating their potential impact on model training.</p>

<p><strong>Meta-Learning Formulation</strong>: Instead of relying on human notions of quality, one can also phrase in-domain and transfer data selection as meta-learning problems (<a href="https://arxiv.org/abs/2011.00050">Nguyen et al., 2020</a>). The outer loop selects data for models in the inner loop to train on. Meta-learning approaches have traditionally been very computationally expensive. Recent work, dubbed datamodels (<a href="https://arxiv.org/abs/2202.00622">Ilyas et al., 2022</a>), seeks to make this bi-level optimization problem more tractable by directly training a model to predict the test performance that would result from excluding or including a particular datapoint. Subsequent work (<a href="https://arxiv.org/abs/2303.14186">Park et al., 2023</a>) made this approach computationally efficient, and recently, <a href="https://arxiv.org/abs/2401.12926">Engstrom et al., 2024</a> used this approach to score pre-training examples based on how they affect performance on a target set of examples. Our work, LESS, can be interpreted as one such meta-learning formulation for selecting data in the instruction tuning setting.</p>

<h3 id="instruction-tuning">Instruction Tuning</h3>

<p>Instruction tuning stands as a pivotal process in unlocking capabilities of pre-trained base models by further training the models to make them follow human instructions. Many works have assembled massive instruction tuning datasets. Some early datasets are human annotated (e.g., Open Assistant and Dolly), though recent trends mostly use completions from GPT models (e.g., Orca, ShardGPT, UltraChat etc.). The queries in these datasets cover a broad spectrum of topics, and could be as diverse as pre-training datasets. They are mostly used to build general-purpose chatbots.</p>

<p>Recently, a lot of works have shown that high-quality data is essential for instruction tuning. The pioneering work LIMA (<a href="https://arxiv.org/abs/2305.11206">Zhou et al., 2023</a>) illustrates that a mere 1,000 meticulously selected high-quality human-curated examples could lead to marked performance improvements. Numerous studies have thus endeavored to automate the data selection pipeline, including strategies for choosing examples based on their naturalness (<a href="https://arxiv.org/abs/2307.06290">Cao et al., 2023</a>), employing GPT-4 for quality scoring (<a href="https://arxiv.org/abs/2307.08701">Chen et al., 2023</a>), enhancing data diversity (<a href="https://arxiv.org/abs/2311.14736">Bukharin et al., 2023</a>, <a href="https://arxiv.org/abs/2312.15685">Liu et al., 2023</a>),  and ensuring broad coverage (<a href="https://arxiv.org/abs/2311.15653">Du et al., 2023</a>). Additionally, some research has explored the benefits of prioritizing longer examples (<a href="https://arxiv.org/abs/2402.04833">Zhao et al., 2024</a>), but it remains uncertain whether if this simply aligns on a surface level with the tendency of GPT to favor longer outputs (<a href="https://arxiv.org/abs/2306.04751">Wang et al., 2023</a>).</p>

<h2 id="transfer-data-selection">Transfer Data Selection</h2>

<p>Transfer data selection and in-domain data selection differ in purpose. While in-domain data selection aims to cover the properties of the entire dataset, transfer data selection focuses on enhancing the performance of a specific subdistribution of data. This shift in focus leads to a change in the selection criterion from representativeness to <strong>relevance</strong>.</p>

<p>In transfer data selection, the goal is to identify the most relevant data points from a large pool of available data. This approach is particularly useful for building domain-specific models or improving the performance of specific tasks or queries. To achieve this, a subset of target data is typically required to serve as an anchor for the data selection process. Previous works in this area include the study by <a href="https://aclanthology.org/2020.acl-main.740/">Gururangan et al. (2020)</a>, which demonstrates the effectiveness of continued training on topic-specific pre-training data to improve performance on domain-specific downstream tasks. Another notable work is by <a href="https://arxiv.org/abs/2302.03169">Xie et al. (2023)</a>, which introduces a data reweighting approach based on the n-gram similarity between the source data and the target distribution. While these two works focus on aligning data with surface form cues (i.e., topic and ngram matching), LESS selects data that matches the underlying task or reasoning type.</p>

<h1 id="conclusion-and-future-directions">Conclusion and Future Directions</h1>

<p>Data plays a crucial role in determining the capabilities of trained deep models. In the in-domain setting, data selection aims to select a small yet representative dataset. Reducing the dataset size directly reduces the time required for training, which can be extremely useful when pre-training LLMs. On other hand, in the transfer setting, one seeks to solve tasks that do not have much data associated with them, and this requires <em>filtering</em> the dataset to identify a <strong>relevant</strong> subset to train on. Our method, LESS, selects data in the transfer setting to perform targeted instruction tuning, and it identifies the most relevant 5% of the dataset that can induce better performance than training on the full dataset. More broadly, we see data as being an important area of study for improving LLMs. Spending more compute on data selection (or, more broadly, data generation) in many different settings has proven to be very valuable, though one has to ensure that the cost of selection does not skyrocket. Data selection can also go beyond improving or preserving performance to attribute particular model behaviors to the training data. For example, a recent follow-up to LESS (<a href="https://arxiv.org/abs/2404.01099">He et al., 2024</a>) identifies seemingly benign data that somehow breaks the safety of models during fine-tuning. We’re excited to see where data selection goes next!</p>

<p><strong>Acknowledgements</strong>: LESS is co-authored with Suchin Gururangan, Sanjeev Arora, and Danqi Chen. We thank (in alphabetical order) Dan Friedman, Tianyu Gao, Lucy He, Austin Wang, Alex Wettig, and Howard Yen for their helpful feedback on this post!</p>

<hr />
<p><strong>Footnotes</strong>:</p>

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>In some cases, the distribution of the training data may not match that of the evaluation data. However, the training data could still serve as a good approximation and correlates with the performance on the evaluation data. For instance, the pre-training loss measured on a held-out dataset, typically provides a reliable indication of the model’s performance on downstream tasks. Therefore, we still consider pre-training data selection as in-domain data selection. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>We use the efficient random projection implementation used in TRAK (<a href="https://arxiv.org/abs/2303.14186">Park et al., 2023</a>). See their amazing codebase <a href="https://github.com/MadryLab/trak">here</a>! <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>According to the derivation, the training gradients are normalized using the Adam update rule, and the validation gradients for the target instances are used as-is. Both are compressed via random projection. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:4" role="doc-endnote">
      <p>A <a href="https://arxiv.org/abs/2402.16827">recent survey paper</a> provides a more comprehensive and formal treatment of data selection methods in the context of language models. <a href="#fnref:4" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name>&lt;a href=&quot;https://xiamengzhou.github.io&quot;&gt;Mengzhou Xia&lt;/a&gt; and Sadhika Malladi</name></author><summary type="html"><![CDATA[TL;DR: We describe how data selection for modern-day LLMs differs from prior settings and how our algorithm, LESS, effectively selects relevant data to cultivate specific capabilities in models during instruction tuning.]]></summary></entry><entry><title type="html">How to Scale Hyperparameters as Batch Size Increases</title><link href="cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/" rel="alternate" type="text/html" title="How to Scale Hyperparameters as Batch Size Increases" /><published>2024-01-22T00:00:00-08:00</published><updated>2024-01-22T00:00:00-08:00</updated><id>cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2024/01/22/SDEs-ScalingRules/"><![CDATA[<p><strong>TL;DR:</strong> Stochastic differential equations (SDEs) provide rigorous, empirically validated <strong>scaling rules</strong> that prescribe how to adjust hyperparameters when scaling training runs (Adam or SGD, language or vision) to highly distributed settings without sacrificing performance. This post focuses on empirically useful insights, and a subsequent post will describe the theoretical toolbox of SDEs in more detail.</p>

<h1 id="scaling-rules-increase-batch-size-without-hurting-performance">Scaling Rules: Increase Batch Size without Hurting Performance</h1>

<p>Even as early as 2011, researchers recognized that scaling training runs across GPUs can yield huge efficiency gains (<a href="https://arxiv.org/abs/1106.5730">HOGWILD! by Niu et al.</a>). For example, loading a large minibatch using data parallel with 8x as many GPUs allows you to finish training nearly 8x as fast (modulo communication and latency). However, using a very large batch size naively hurts SGD performance and puts a limit on how much you can scale (<a href="https://arxiv.org/abs/1609.04836">Keskar et al., 2017</a>). A few papers subsequently suggested that one needs a <strong>scaling rule</strong> to adjust the hyperparameters when increasing the batch size. There are different scaling rules for different optimizers.</p>

<hr />

<p><strong>Linear Scaling Rule (for SGD)</strong></p>

<p>When scaling the batch size by $\kappa$, scale the learning rate also by $\kappa$.</p>

<p><strong>Square Root Scaling Rule (for Adam)</strong></p>

<p>When scaling the batch size by $\kappa$, scale the learning rate by $\sqrt{\kappa}$. Also, change the other hyperparameters, setting $\beta_1 = 1 - \kappa(1-\beta_1)$, $\beta_2 = 1-\kappa(1-\beta_2)$, and $\epsilon = \epsilon / \sqrt{\kappa}$.</p>

<hr />

<p>Even so, without rigorous theory, it was unknown what the maximal performant batch size was, so scaling runs up was an expensive trial-and-error game. In 2014, <a href="https://arxiv.org/abs/1404.5997">Krizhevsky heuristically derived</a> a <strong><em>square root scaling rule</em> for SGD</strong>, stating that the learning rate should be scaled by $\sqrt{\kappa}$ when scaling the batch size by $\kappa$ (see the bottom of page 5). <strong>This ends up being incorrect!</strong> Even Krizhevsky notes that the <strong>linear scaling rule yields empirically stronger performance.</strong> But later work in (<a href="https://proceedings.neurips.cc/paper/2017/hash/a5e0ff62be0b08456fc7f1e88812af3d-Abstract.html">Hoffer et al., 2017</a>) agreed with the square root scaling rule.</p>

<p>At the same time, an empirical work trying to train a ResNet-50 on ImageNet in 1 hour (i.e., in a highly distributed setting), <strong>derived the linear scaling rule under the assumption that the gradient doesn’t change much during training</strong> (<a href="https://arxiv.org/abs/1706.02677">Goyal et al., 2017</a>). Despite a few other optimization tricks, <strong>the test accuracy still degraded at large batch size.</strong> (<a href="https://arxiv.org/abs/2006.15081">Smith et al., 2020</a>) also derived the linear scaling rule using reasoning analogous to a central limit theorem but still noted the <strong>batch size needs to be small</strong> for the rule to hold.</p>

<p>To clear up which scaling rule is correct and when it will break, we can turn to SDEs! <strong><a href="https://openreview.net/forum?id=goEdyJ_nVQI">Our work in NeurIPS 2021</a> used SDEs to design a simple test (requiring just one baseline run!) for the largest batch size you can parallelize to via the linear scaling rule without sacrificing performance.</strong> See the figure below. We also designed an efficient simulation of the SDE that provided evidence that <strong>the SDE is the correct way to model many realistic SGD training settings.</strong> (The next section explains why SDEs are so useful in analyzing SGD.)</p>

<center>
<div class="figure">
<img src="/~smalladi/assets/sde_img/cifar10_lsr.png" alt="Using SDE theory to predict the failure of the linear scaling rule using just one baseline run." style="
 margin-left: auto;
 margin-right: auto;
 width: 90%;" />
 <br />
 
 <div class="caption">
 <span class="caption-label">Figure from <a href="https://openreview.net/forum?id=goEdyJ_nVQI">our work in NeurIPS 2021</a>.</span>
 Predicting the failure of the linear scaling rule with just one baseline run, using insights from SDEs! The red dashed line indicates where the necessary condition for the scaling rule fails, and the shaded red area covers the batch sizes at which the test error has increased by 20% or more from its baseline value. These experiments are on CIFAR-10 but there are plenty more settings in the paper!</div> </div></center>

<p>In the meantime, language models started to grow popular. (<a href="https://arxiv.org/abs/1904.00962">You et al., 2020</a>) designed a scheme to train a BERT model in 76 minutes with Adam, and they empirically discovered that <strong>scaling the learning rate by $\sqrt{\kappa}$ works well</strong>. <a href="https://openreview.net/forum?id=F2mhzjHkQP">Our work in NeurIPS 2022</a> approached the question theoretically and established new SDE approximations for Adam and RMSprop. These yielded <strong>a square root scaling rule for Adam, which requires scaling the other optimization hyperparameters in addition to the learning rate.</strong> Experiments showed that <strong>the square root scaling rule preserved test accuracy, perplexity, and even post-fine-tuning performance.</strong> Naturally, these scaling rules will break at some large batch size, but we couldn’t find any empirical setting at the time where this happened.</p>

<p>Various works have since used the SDE approximation to derive useful distributed training protocols when using EMA (<a href="https://openreview.net/forum?id=DkeeXVdQyu">Busbridge et al., 2023</a>) and Local SGD (<a href="https://arxiv.org/abs/2310.14423">Gu et al., 2023</a>).</p>

<h1 id="into-the-weeds-with-sdes">Into the Weeds with SDEs</h1>

<p>Now that I’ve described the importance of SDEs, I’ll describe what they are exactly and how they can be used. SDEs describe a continuous trajectory of the model parameters over the course of training. The hypothesis is that this continuous trajectory is a reasonable and easily analyzable approximation of the discrete parameter trajectory that SGD prescribes. So let’s see how it shakes out.</p>

<p>At each step, SGD samples a minibatch $B_t\subset \mathcal{D}$ and updates the parameters according to some loss function $\ell$: $\theta_{t+1} = \theta_t - \eta\nabla \ell(B_t;\theta_t)$. Everyone knows the crucial hyperparameter $\eta$, the learning rate, but people often overlook the batch size hyperparameter, $B$, which is usually set to be the largest allowable value on the GPU (for pre-training) and carefully grid-searched (in fine-tuning). These two hyperparameters together control how much noise there is in the gradient estimate and how it affects the trajectory. The <strong>gradient noise</strong> is what makes SGD different from GD, so we will try to study this property carefully to understand why SGD results in better generalization than GD.</p>

<p>One approach to studying SGD is to use a continuous approximation of the discrete trajectory. This admits the derivation of results about the exploration and convergence of the optimization. One way to get a continuous approximation is to take the learning rate to be very small (i.e., $\eta\to 0$), which gets us to the famous <strong>gradient flow</strong> (GF) limit: $dX_t = -\nabla\ell(\mathcal{D};X_t)dt$. I’ll start to use $X$ to denote the continuous trajectory of the parameters and $\theta$ to denote the discrete one. GF used to be and still somewhat is the tool of choice to analyze how optimization proceeds. But if we look closely, we can see that GF is agnostic to the batch size! So, even if I was doing full-batch GD, I would still end up with GF as the limit. This means that GF can’t tell us much about the benefit of SGD over GD.</p>

<p>OK, so we need to find a continuous process that can actually model the <strong>gradient noise</strong>. This is where SDEs come in handy! Here’s the SDE used to approximate SGD (<a href="https://jmlr.org/papers/v20/17-526.html">Li et al., 2019</a>):</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>d</mi><msub><mi>X</mi><mi>t</mi></msub><mo>=</mo><munder><munder><mrow><mo>−</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi mathvariant="script">D</mi><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mi>d</mi><mi>t</mi></mrow><mo stretchy="true">⏟</mo></munder><mtext>Drift: Gradient Flow</mtext></munder><mo>+</mo><munder><munder><mrow><mo stretchy="false">(</mo><mi>η</mi><mi mathvariant="normal">Σ</mi><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mi mathvariant="normal">/</mi><mn>2</mn></mrow></msup><mi>d</mi><msub><mi>W</mi><mi>t</mi></msub></mrow><mo stretchy="true">⏟</mo></munder><mtext>Diffusion: Brownian Motion</mtext></munder></mrow><annotation encoding="application/x-tex">
dX_t = \underbrace{-\nabla \ell(\mathcal{D};X_t)dt}_{\text{Drift: Gradient Flow}} + \underbrace{(\eta\Sigma(X_t))^{1/2} dW_t}_{\text{Diffusion: Brownian Motion}}
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.84444em;vertical-align:-0.15em;"></span><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.334108em;vertical-align:-1.584108em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span style="top:-1.415892em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Drift: Gradient Flow</span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.75em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13  35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688  0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7 -331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z"></path></svg></span><span class="brace-center" style="height:0.548em;"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214 c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14  53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3  11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0 -5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z"></path></svg></span><span class="brace-right" style="height:0.548em;"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3  28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237 -174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z"></path></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">−</span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord mathdefault">d</span><span class="mord mathdefault">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.584108em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:2.522108em;vertical-align:-1.584108em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.9379999999999997em;"><span style="top:-1.415892em;"><span class="pstrut" style="height:3em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">Diffusion: Brownian Motion</span></span></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord munder"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span class="svg-align" style="top:-2.102em;"><span class="pstrut" style="height:3em;"></span><span class="stretchy" style="height:0.548em;min-width:1.6em;"><span class="brace-left" style="height:0.548em;"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMinYMin slice"><path d="M0 6l6-6h17c12.688 0 19.313.3 20 1 4 4 7.313 8.3 10 13  35.313 51.3 80.813 93.8 136.5 127.5 55.688 33.7 117.188 55.8 184.5 66.5.688  0 2 .3 4 1 18.688 2.7 76 4.3 172 5h399450v120H429l-6-1c-124.688-8-235-61.7 -331-161C60.687 138.7 32.312 99.3 7 54L0 41V6z"></path></svg></span><span class="brace-center" style="height:0.548em;"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMidYMin slice"><path d="M199572 214 c100.7 8.3 195.3 44 280 108 55.3 42 101.7 93 139 153l9 14c2.7-4 5.7-8.7 9-14  53.3-86.7 123.7-153 211-199 66.7-36 137.3-56.3 212-62h199568v120H200432c-178.3  11.7-311.7 78.3-403 201-6 8-9.7 12-11 12-.7.7-6.7 1-18 1s-17.3-.3-18-1c-1.3 0 -5-4-11-12-44.7-59.3-101.3-106.3-170-141s-145.3-54.3-229-60H0V214z"></path></svg></span><span class="brace-right" style="height:0.548em;"><svg width="400em" height="0.548em" viewBox="0 0 400000 548" preserveAspectRatio="xMaxYMin slice"><path d="M399994 0l6 6v35l-6 11c-56 104-135.3 181.3-238 232-57.3  28.7-117 45-179 50H-300V214h399897c43.3-7 81-15 113-26 100.7-33 179.7-91 237 -174 2.7-5 6-9 10-13 .7-1 7.3-1 20-1h17z"></path></svg></span></span></span><span style="top:-3em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mopen">(</span><span class="mord mathdefault" style="margin-right:0.03588em;">η</span><span class="mord">Σ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mtight">/</span><span class="mord mtight">2</span></span></span></span></span></span></span></span></span><span class="mord mathdefault">d</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.13889em;">W</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.13889em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.898em;"><span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.584108em;"><span></span></span></span></span></span></span></span></span></span></p>

<p>The first term of our SDE is the <strong>drift</strong>, the deterministic term in the process, which is just the full-batch gradient in this case. The second term is the <strong>diffusion</strong>, which we traditionally model using Brownian motion $W_t$. So, the SDE is actually very intuitive: we believe that SGD is doing something like GD + noise and we can clearly see that intuition in these two terms. Another key feature is that the learning rate $\eta$ actually shows up here! As we increase the learning rate, the noise in the SDE increases, which also makes sense: when we take larger steps with a mini-batch gradient, the trajectory increasingly diverges from full-batch GD. The last remaining mystery in this equation is $\Sigma(X_t)$, which is the <strong>gradient noise covariance</strong>.</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="normal">Σ</mi><mrow><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="double-struck">E</mi><mi>γ</mi></msub><mo stretchy="false">[</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi mathvariant="script">D</mi><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><msub><mi>B</mi><mi>t</mi></msub><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi mathvariant="script">D</mi><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><msub><mi>B</mi><mi>t</mi></msub><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><msup><mo stretchy="false">)</mo><mi mathvariant="normal">⊤</mi></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">
\Sigma^{(B)}(X_t) = \mathbb{E}_\gamma  [(\nabla \ell(\mathcal{D}; X_t) - \nabla \ell(B_t; X_t)(\nabla \ell(\mathcal{D}; X_t) - \nabla \ell(B_t;X_t))^\top]
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1.036108em;vertical-align:-0.286108em;"></span><span class="mord"><span class="mord"><span class="mord mathbb">E</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.15139200000000003em;"><span style="top:-2.5500000000000003em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05556em;">γ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.286108em;"><span></span></span></span></span></span></span><span class="mopen">[</span><span class="mopen">(</span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mopen">(</span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:1.149108em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991079999999999em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">⊤</span></span></span></span></span></span></span></span><span class="mclose">]</span></span></span></span></span></p>

<p>where $\gamma$ denotes the optimization seed (which determines the minibatch $B_t$). We can assume the gradient for a single datapoint is the full batch gradient plus some Gaussian noise (discussed more at the end of the post). Then, if we take a minibatch $B_t$ with size $B$, the minibatch gradient is:</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><msub><mi>B</mi><mi>t</mi></msub><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∇</mi><mi mathvariant="normal">ℓ</mi><mo stretchy="false">(</mo><mi mathvariant="script">D</mi><mo separator="true">;</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>+</mo><mfrac><mn>1</mn><mi>B</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>B</mi></munderover><msub><mi>z</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">
\nabla \ell(B_t;X_t) = \nabla \ell(\mathcal{D}; X_t) +  \frac{1}{B} \sum_{i=1}^B z_i
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.05017em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em;"></span><span class="mord">∇</span><span class="mord">ℓ</span><span class="mopen">(</span><span class="mord"><span class="mord mathcal" style="margin-right:0.02778em;">D</span></span><span class="mpunct">;</span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222222222222222em;"></span></span><span class="base"><span class="strut" style="height:3.106005em;vertical-align:-1.277669em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.05017em;">B</span></span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283360000000002em;"><span style="top:-1.872331em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathdefault mtight">i</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.050005em;"><span class="pstrut" style="height:3.05em;"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3000050000000005em;margin-left:0em;"><span class="pstrut" style="height:3.05em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.277669em;"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.16666666666666666em;"></span><span class="mord"><span class="mord mathdefault" style="margin-right:0.04398em;">z</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.31166399999999994em;"><span style="top:-2.5500000000000003em;margin-left:-0.04398em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span></span></span></span></span></p>

<p>where $z_i\sim \mathcal{N}(0, \Sigma(X_t))$ is drawn i.i.d. per datapoint. Then, when we scale the batch size, we can see how the gradient noise, and thus the diffusion term in the SDE, changes.</p>

<p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="normal">Σ</mi><mrow><mo stretchy="false">(</mo><mi>κ</mi><mi>B</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mn>1</mn><mi>κ</mi></mfrac><msup><mi mathvariant="normal">Σ</mi><mrow><mo stretchy="false">(</mo><mi>B</mi><mo stretchy="false">)</mo></mrow></msup><mo stretchy="false">(</mo><msub><mi>X</mi><mi>t</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\Sigma^{(\kappa B)}(X_t) = \frac 1\kappa \Sigma^{(B)}(X_t)
</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.188em;vertical-align:-0.25em;"></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight">κ</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2777777777777778em;"></span></span><span class="base"><span class="strut" style="height:2.00744em;vertical-align:-0.686em;"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.32144em;"><span style="top:-2.314em;"><span class="pstrut" style="height:3em;"></span><span class="mord mathdefault">κ</span></span><span style="top:-3.23em;"><span class="pstrut" style="height:3em;"></span><span class="frac-line" style="border-bottom-width:0.04em;"></span></span><span style="top:-3.677em;"><span class="pstrut" style="height:3em;"></span><span class="mord">1</span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em;"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mord"><span class="mord">Σ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.938em;"><span style="top:-3.113em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathdefault mtight" style="margin-right:0.05017em;">B</span><span class="mclose mtight">)</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathdefault" style="margin-right:0.07847em;">X</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.2805559999999999em;"><span style="top:-2.5500000000000003em;margin-left:-0.07847em;margin-right:0.05em;"><span class="pstrut" style="height:2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathdefault mtight">t</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em;"><span></span></span></span></span></span></span><span class="mclose">)</span></span></span></span></span></p>

<p>This equation also matches our intuitions: when we increase the batch size, the noise (i.e., diffusion) in the process should get smaller, since the trajectory is closer to full-batch GD. Now we have basically everything we need in order to derive some scaling rules!</p>

<h2 id="deriving-scaling-rules-from-sdes">Deriving Scaling Rules from SDEs</h2>

<p>Now that we have the basics of SDEs down, we can go back to the scaling rules at the start of the post.</p>

<hr />

<p><strong>Linear Scaling Rule (for SGD)</strong></p>

<p>When scaling the batch size by $\kappa$, scale the learning rate also by $\kappa$.</p>

<p><strong>Square Root Scaling Rule (for Adam)</strong></p>

<p>When scaling the batch size by $\kappa$, scale the learning rate by $\sqrt{\kappa}$. Also, change the other hyperparameters, setting $\beta_1 = 1 - \kappa(1-\beta_1)$, $\beta_2 = 1-\kappa(1-\beta_2)$, and $\epsilon = \epsilon / \sqrt{\kappa}$.</p>

<hr />

<p>The reasoning to derive scaling rules from the SDE goes like this. Changing the batch size scales $\Sigma(X_t)$ by $1/\kappa$ so one should scaling the learning rate proportionally to <strong>preserve the scale of the diffusion term</strong>. Language models are usually trained with the Adam optimizer, which requires a different SDE approximation (see our NeurIPS 2022 paper <a href="https://openreview.net/forum?id=F2mhzjHkQP">here</a>). That SDE, through similar reasoning, yields the square root scaling rule.</p>

<p>Keep in mind that the accuracy of the SDE approximation is a sufficient condition for the scaling rule: if the SDE is a good approximation, then the scaling rule should hold. So when does the SDE approximation break? <a href="https://openreview.net/forum?id=F2mhzjHkQP">Section 4.1 of our paper</a> illustrates a good warmup setting to build intuition on when the gradient noise gets to be too small and the SDE approximation is no longer good. If you find your hyperparameters taken to extremes by these scaling rules, consider shifting your baseline run to a larger batch size.</p>

<h1 id="what-do-scaling-rules-preserve">What do Scaling Rules Preserve?</h1>

<p>Traditionally, when training vision models with SGD, the empirical goal of using a scaling rule is to preserve the test accuracy of the model. But for language models trained with Adam, <strong>what metrics are we interested in?</strong> Perplexity? In-context learning ability? Or even more broadly, factuality? Truthfulness? Fortunately, when we use the formal language of SDEs, we can show results that conceptually encapsulate all of these possibilities (and ones we haven’t dreamed up yet).</p>

<p>To recap, the way that one gets from SDEs to scaling rules is as follows. Changing the batch size changes the equation of the SDE. Adjusting the optimization hyperparameters according to the scaling rule changes the equation of the SDE back to what it was originally with the baseline run. If the SDE is indeed a <em>faithful approximation</em> of SGD/Adam, then preserving the SDE equation under changing batch sizes will also preserve the optimization trajectory of the baseline run of SGD/Adam.</p>

<p>So now we enter the question of what a “faithful approximation” is. As I hinted before, we might only care about <strong>preserving certain features of our trained model</strong> (e.g., test accuracy or truthfulness) under changing batch sizes. And we have <strong>no idea how these features change with the actual parameters</strong> — for example, two models may have parameters that are very close to each other but have different test accuracies. Yet another complicating factor is that <strong>SGD and Adam are stochastic</strong> (i.e., depend on the optimization seed), so we have to figure out what it means for two stochastic trajectories to approximate each other.</p>

<p>Altogether, we need a more sophisticated notion of approximation than just saying the two trajectories are close to each other in $\ell_2$ norm. SDEs handle this issue using <strong>test functions</strong>, which compute something as a function of the model parameters. This notion of approximation, called a <strong>weak approximation</strong> (<a href="https://jmlr.org/papers/v20/17-526.html">Li et al., 2019</a>), gives a guarantee that the SDEs and SGD/Adam produce models that have close values of all possible test functions. This is a very broad class of functions, and it likely includes all of the ones we would care about. The tricky thing is, to make the theory work out, we have to assume something fairly general about these test functions — that they grow at most polynomially with the model parameters — and we can’t be confident that test accuracy, truthfulness, etc. satisfy this assumption. But, fortunately, <strong>extensive experiments in our papers (<a href="https://openreview.net/forum?id=goEdyJ_nVQI">on SGD</a> and <a href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/32ac710102f0620d0f28d5d05a44fe08-Abstract-Conference.html">on Adam</a>) show that scaling rules preserve various test functions, including test accuracy, perplexity, and even post-fine-tuning performance</strong> (on GLUE tasks).</p>

<center>
<div class="figure">
<img src="/~smalladi/assets/sde_img/roberta.png" alt="Training RoBERTa models on Wiki+Books with different batch sizes using the square root scaling rule." style="
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
 <img src="/~smalladi/assets/sde_img/gpt.png" alt="Training RoBERTa models on Wiki+Books with different batch sizes using the square root scaling rule." style="
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
 <br />

 <div class="caption">
 <span class="caption-label">Figures from <a href="https://openreview.net/forum?id=F2mhzjHkQP">our NeurIPS 2022 paper.</a></span>
Training RoBERTa models on Wiki+Books (left) and GPT-2 on WikiText-103 (right) with different batch sizes. Adjusting the Adam optimizer hyperparameters per the square root scaling rule ensures performance is preserved!
</div>
</div>
</center>

<h1 id="discussions-and-extensions">Discussions and Extensions</h1>

<p>Here we discuss some of the more nuanced points of SDEs for those who are interested. I will dive more into these ideas in a subsequent post, which will contain more of the theoretical underpinnings of SDEs.</p>

<ol>
  <li>
    <p><strong>Is SGD gradient noise actually Gaussian?</strong> In the SDE section, I assumed that the gradient of one datapoint is the full-batch gradient plus some Gaussian noise. It is generally agreed that gradient noise is additive, but a big topic of discussion in the SDE community is whether the gradient noise is actually Gaussian or if it’s “heavy-tailed” (i.e., third-and-higher moments are non-negligible). The SDE derived above, called an Ito SDE, uses <a href="https://en.wikipedia.org/wiki/Brownian_motion">Brownian motion</a> for the diffusion term, but some argue that we should instead use a the more general <a href="https://en.wikipedia.org/wiki/Lévy_process">Levy process</a> for the diffusion, which yields a Levy SDE (<a href="http://proceedings.mlr.press/v97/simsekli19a/simsekli19a.pdf">Simsekli et al., 2019</a>). These are usually harder to analyze, and much of the empirical evidence motivating the usage of a Levy SDE has been disproven (<a href="https://openreview.net/forum?id=wXgk_iCiYGo">Xie et al., 2021</a>). Moreover, <a href="https://openreview.net/forum?id=goEdyJ_nVQI">our work in NeurIPS 2021</a> showed empirically that using Gaussian noise with the first and second moments matching the naturally occurring noise in SGD is sufficient to preserve the generalization performance of SGD in vision. For these reasons, and also because of the ease of using an Ito SDE for analysis, the Ito SDE remains the common choice for approximating discrete optimization trajectories. More recently, however, the SGD noise has been considered to be heavy-tailed when nodes in a distributed setting fail unexpectedly (<a href="https://openreview.net/forum?id=C6PiH9Fkjd">Schaipp et al., 2023</a>). Due to the computational resources to make these measurements, it’s hard to collect evidence of which setting is more faithful to language modeling training, but our insights derived using Ito SDEs (<a href="https://openreview.net/forum?id=F2mhzjHkQP">in our NeurIPS 2022 paper</a>) generally preserve the performance of language models when performing pre-training and fine-tuning. Other analyses using similar noise assumptions, including our <a href="https://arxiv.org/abs/2307.15196">upcoming ICLR 2024 paper</a> showing that using momentum does not change the SGD trajectory when using small learning rates, also empirically hold when training language models.</p>
  </li>
  <li>
    <p><strong>Implicit Bias of SGD</strong>: The SDE that I described doesn’t directly give much information about the implicit bias (i.e., the ability of SGD to choose generalizing solutions out of many possible empirical risk minimizers). Recent works have studied using the SDE to describe the late phase of training, where the training loss is nearly zero, and the primary term driving the trajectory is the diffusion (<a href="https://openreview.net/forum?id=siCt4xZn5Ve">Li et al., 2022</a>). Analyzing this SDE reveals that SGD tends towards flatter minima. It is not totally clear how flatness and generalization are related to each other (<a href="https://openreview.net/forum?id=SJgIPJBFvH">Jiang et al., 2020</a>; <a href="https://openreview.net/forum?id=VZp9X410D3">Andriushchenko et al., 2023</a>; <a href="https://openreview.net/forum?id=Dkmpa6wCIx">Wen et al., 2023</a>), but a careful analysis of the SDE may yield a more nuanced understanding than classical generalization measures.</p>
  </li>
</ol>

<h1 id="conclusion">Conclusion</h1>

<p>SDEs are a powerful, generalizable tool for studying stochastic optimization. The results are mostly agnostic to the model architecture and dataset, so just a little bit of understanding goes a long way and provides useful empirical insights. In a separate post, I’ll talk a bit more about the proof techniques and rigorous considerations involved in using SDEs to approximate discrete optimization.</p>

<p><strong>Acknowledgements</strong>: Thanks (in alphabetical order) to Tianyu Gao, Surbhi Goel, Bingbin Liu, Kaifeng Lyu, Abhi Venigalla, Mengzhou Xia, and Howard Yen for their feedback on this post! I’m deeply indebted to Zhiyuan Li for patiently teaching me about SDEs and their technical features. Feedback from Twitter prompted me to add a link to the section in our paper that provides an easy setting to work out the scaling rule in.  The works I mention in this paper were co-authored with (in alphabetical order) Sanjeev Arora, Zhiyuan Li, Kaifeng Lyu, Abhishek Panigrahi, Runzhe Wang, and Tianhao Wang.</p>]]></content><author><name>Sadhika Malladi</name></author><summary type="html"><![CDATA[TL;DR: Stochastic differential equations (SDEs) provide rigorous, empirically validated scaling rules that prescribe how to adjust hyperparameters when scaling training runs (Adam or SGD, language or vision) to highly distributed settings without sacrificing performance. This post focuses on empirically useful insights, and a subsequent post will describe the theoretical toolbox of SDEs in more detail.]]></summary></entry><entry><title type="html">British Round-Up</title><link href="cs.princeton.edu/~smalladi/blog/2023/02/01/chai/" rel="alternate" type="text/html" title="British Round-Up" /><published>2023-02-01T00:00:00-08:00</published><updated>2023-02-01T00:00:00-08:00</updated><id>cs.princeton.edu/~smalladi/blog/2023/02/01/chai</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2023/02/01/chai/"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>I’m in London for a month, but it only took me two days to realize that British food is very fried (gluten!) and lacks vegetables. There are plenty of restaurants with creative dishes and vegetables, but they are not quintessentially British. So, I’m hard-pressed to see how I can sample gluten-free British cuisine. I focused on chai, fish &amp; chips, and high tea. There’s not much to say about high tea other than the fact that I did go to the one at The Royal Horseguards Hotel and it was indeed gluten-free. But overall, I realized that high tea is not that great. The tea itself is not really that important, and the little sandwiches and pastries are not to my taste. I don’t even get what the point is of combining tea with weird mayonnaise-y savory foods.</p>

<p>Although I didn’t set out to find it, I had some great Chinese food in London too! I had gluten free dumplings at Ping Pong and hot pot at Haidilao! Ping Pong was fantastic and had lots of options in my opinion. Haidilao is not as good as other hot pot places, because they don’t really make a super spicy soup like I want. But I got to see a <em>bian lian</em> performer and received some memorabilia at Haidilao, so it will always be a special memory to me!</p>

<p><img src="/~smalladi/assets/british/ping_pong.JPG" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 65%;" /></p>
<center>GF Dumplings at Ping Pong.</center>

<h1 id="fish--chips">Fish &amp; Chips</h1>
<p>I’m a bit lazy to go into the details of all the fish and chips places I went to, but I followed <a href="https://www.mygfguide.com/london-gluten-free-fish-and-chips/">this guide</a>. It’s a little outdated, so be sure to call ahead. We tried out Indigo, Mayfair Chippy, and Old Shades. Old Shades was by far the most fun place to go, because there was no line, and our bartender performed some incredible magic for us! The fish &amp; chips were great for the price, but I think Indigo had the best overall taste. Mayfair Chippy was kind of unpleasant because we sat outside in the cold, and they gave a giant piece of fish that just fell apart as soon as I tried to pick it up. I guess there is such a thing as too tender! But they had a great tomato curry sauce that was non-traditional but really delicious. Overall, I definitely still like fish and chips, and I think they’re worth the hype, but I also cannot and will not eat the weird mushy green peas that always come with them.</p>

<p><img src="/~smalladi/assets/british/mayfair.JPG" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 65%;" /></p>
<center>Fish &amp; Chips from Mayfair Chippy. Great tomato sauce!</center>

<h1 id="chai">Chai</h1>
<p>Chai is obviously not “native” British cuisine. But I did come across many chai vendors who were cooking up the real deal, so I decided to give it a try. I love tea, and of course, British tea is of high quality. I’m also living in a neighborhood close to Whitechapel, one of the South Asian neighborhoods in London.</p>

<p>I’m not really a chai expert. I approached each chai with the following very subjective criteria:</p>

<ol>
  <li><strong>Spices</strong>: The chai should be <em>garam</em> unless otherwise specified. Some combination of ginger, cardamom, and cloves should pierce the eternal veil of British rain to warm me up. This is usually the criterion that is violated by the “chai tea lattes” of the world.</li>
  <li><strong>Texture</strong>: Pure tea enthusiasts would scoff at the idea of adding milk to tea, but it is a crucial part of the chai experience. It should be creamy and velvety, not watery.</li>
  <li><strong>Vibe</strong>: There is just a certain vibe that comes with drinking chai. It shouldn’t be overengineered or curated.</li>
</ol>

<h2 id="karak-chai">Karak Chai</h2>
<p>I encountered my first chai experience near the Whitechapel open-air market on the weekend. I saw a sign for chai, so I rounded the corner to what was really an underwhelming chai “shop”. But I had the craving so I forged on. I got my chai but couldn’t pay there with my credit card. Instead, the owner sent me around the corner to a mobile SIM shop to pay. The SIM shop sent me back with a receipt. The whole thing was kind of endearing though inconvenient. It cost 1 pound and 5 minutes of my time.</p>

<p>This chai was the kind that you want to drink ASAP. When it’s hot, the texture is great, and the vibe is strong. The spices were kind of neutralized by sugar and milk, but it was overall very good. Within two minutes of getting it, it cooled off and became decidedly worse. The sugar felt sticky in my mouth and I didn’t like that. I usually like my drinks lukewarm, not scalding, so I wasn’t super happy with this experience. But pretty good for the price, and it gave me the vibe of eating street food (a rare feeling for celiacs).</p>

<h2 id="charista">Charista</h2>
<p>I spotted this place on one of my runs and decided it looked trendy but authentic. They have a few different types of chai, and they also have snacks (which aren’t gluten-free). Intrigued by date molasses, I decided to try the Gurer chai. They served it to me in a normal glass, not a mug, which really enhanced the authentic chai experience: a fearful grip near the lip of the glass followed by the urgency to sip it before your fingertips burn. This chai was really good - I can’t blame them for the lack of spices because the cashier did tell me it would be sweet. The depth of the dates as a sweetener compensated pretty well though.</p>

<p><img src="/~smalladi/assets/british/charista.JPG" alt="legend" style="  margin-left: auto;  margin-right: auto;  width: 49%;" />
<img src="/~smalladi/assets/british/charista_chai.JPG" alt="legend" style="  margin-left: auto;  margin-right: auto;  width: 49%;" /></p>
<center>The outside of Charista (left) and the authentic cup that burns your fingers (right).</center>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction I’m in London for a month, but it only took me two days to realize that British food is very fried (gluten!) and lacks vegetables. There are plenty of restaurants with creative dishes and vegetables, but they are not quintessentially British. So, I’m hard-pressed to see how I can sample gluten-free British cuisine. I focused on chai, fish &amp; chips, and high tea. There’s not much to say about high tea other than the fact that I did go to the one at The Royal Horseguards Hotel and it was indeed gluten-free. But overall, I realized that high tea is not that great. The tea itself is not really that important, and the little sandwiches and pastries are not to my taste. I don’t even get what the point is of combining tea with weird mayonnaise-y savory foods.]]></summary></entry><entry><title type="html">Equi-Table</title><link href="cs.princeton.edu/~smalladi/blog/2022/10/04/equitable/" rel="alternate" type="text/html" title="Equi-Table" /><published>2022-10-04T00:00:00-07:00</published><updated>2022-10-04T00:00:00-07:00</updated><id>cs.princeton.edu/~smalladi/blog/2022/10/04/equitable</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2022/10/04/equitable/"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>I’ve been in Europe for around two and a half weeks but barely had the chance to dictate my own food choices. The first week was spent at a conference that provided all of the meals (cafeteria-style but still pretty good), and the last week was spent on a deadline, so I just ate the food I packed for the trip. I went to Whole Foods before I left and got many varieties of cup noodles, fully cooked curries, and rice. These are actually pretty good in flavor and kept well in the suitcase!</p>

<p>So I finally got the chance to explore the culinary scene around Zurich. I don’t think Switzerland is really a place for foodies — their signature dish, raclette, relies on a very high quality cheese and does not go above and beyond that to incorporate extra flavor. Regardless, I was determined to make the most of my time in Zurich, so I went to Equi-Table.</p>

<p>The first great part about this experience was that I was walking around about 10 minutes away from the restaurant and had a sudden urge to go eat there. I called and got a reservation within 30 minutes (i.e., at opening time), and they were able to adjust the fixed menu to account for a gluten allergy! Most places need a 24-48 hour notice to do that (understandably), so I felt very lucky that they could make it work. I had no stomach issues after this meal, which was great!</p>

<h1 id="the-environment">The Environment</h1>
<p>The area around the restaurant is not as tourist-oriented as the other parts of Zurich that I had seen, so it was nice to get a calmer vibe. The restaurant had all the trappings of fine-dining (e.g., coat check), but it was in a small, somewhat old building. It would have been charming but it did feel a bit out of sync with the modern menu.</p>

<p>The waitstaff was great and remembered my allergy throughout the meal to make it easy on me. Their English was pretty good, though we did whip out Google Translate a few times to decipher uncommon fruits and vegetables.</p>

<p>The restaurant theme is a modern and sustainable take on local Swiss ingredients. I only later realized was that this meant no seafood! I also had some impression that the Alps would grow the greatest produce in the world, but I’m not sure why I would even think that.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup></p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5177.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 65%;" />
<center>The entrance to Equi-Table.</center>
</p>

<h1 id="food">Food</h1>
<p>As usual, the meal started with a bunch of tiny bites that did not count as a course. I ate the broccoli with tweezers, which felt very fancy. The flavor wasn’t very balanced, because it’s hard to make miso compete with charred broccoli, but it was still a nice texture to eat. The bread was just as amazing as it looks: the exterior leaned towards a thicker rustic crust though the inside was fluffy. It came with a whipped butter that made the whole situation taste like cornbread with brown butter. But the best bite, by far, was the polenta chip with the amazing chive yogurt. It looks like a lot of dip for a small number of thin chips, but I finished the dip and found the flavor to go well with the deep-fried chips.</p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5179.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 30%;" />
 <img src="/~smalladi/assets/equitable/IMG_5182.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 30%;" />
 <img src="/~smalladi/assets/equitable/IMG_5183.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 30%;" />
<br />
<center>From left to right: charred broccoli with dehydrated oyster mushrooms and mushroom-miso sauce, gluten-free bread, and polenta chips with a chive yogurt dip.</center>
</p>

<p>From there, we moved on to yet another bite situation. This bite felt so European because it was pork wrapped around some cabbage and topped with mustard powder. The flavor was nice, but the pork could have been crispier somehow.</p>
<p>
<img src="/~smalladi/assets/equitable/IMG_5184.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 30%;" />
<center>Pork wrapped around pickled cabbage and topped with mustard powder.</center>
</p>

<p>Finally, the first course! It was so weird! The dish was tomatoes in many different forms (tomato <em>ice</em>, pickled tomatoes, tomatillos, etc). I think once you have something hearty and warm like the pork bite, it’s hard to go back to something cold and sharp like this. The waiter poured some basil oil over the dish but the basil kept separating from the oil, so he had to keep mixing it intermittently. Once that oil went in, I immediately panicked because it meant my tomato ice would become tomato water very soon! I tried to eat it really quickly, which only highlighted the ill-designed shape of the bowl. Eventually I picked up the bowl and tilted it to get everything out.</p>

<p>At this point I started to worry I would eat 6 courses and go home hungry. Luckily the second course was more substantial. The dish was sweetbread with artichokes, parsley foam, and parsley oil. I think the problem with putting foam and oil in one dish is that the oil pools beneath the foam and becomes a little gross. But I liked the overall flavors a lot!</p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5185.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 49%;" />
<img src="/~smalladi/assets/equitable/IMG_5186.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 49%;" />
<center>Tomato in many ways with basil oil (left) and sweetbread and artichokes with parsley foam (right).</center>
</p>

<p>Now things started to get a bit more substantial. The third course was a mushroom cream with sage and trout roe. The first thing I liked was the incredible amount of sage and sage butter. These were the main flavor generators so it was nice to have them amid a sea of creamy umami. At least after I finished this bowl I felt like I had eaten the equivalent of an appetizer!</p>

<p>The fourth course became even better. It was a truffle risotto! I was so excited to get some familiar, real flavors back into the meal. It was a nice portion, large enough that the earthy truffle was a star but small enough that I didn’t get the typical late-stage risotto regret. It turns out that the Alps actually do boast some truffles. You can see in the picture that they put a lot on top (and that kind of scared me) but the waiter assured me that the Swiss truffles are not as expressive as the Italian ones.</p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5187.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 49%;" />
<img src="/~smalladi/assets/equitable/IMG_5188.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 49%;" />
<center>Mushroom cream with sage (left) and truffle risotto (right).</center>
</p>

<p>At this point I am totally primed for the main dish. And it was pretty worth the wait! It was a venison with a smoked, somehow softened carrot and some harder carrot slices. The waiter poured the jus on the plate for me. Overall the dish was great, and I of course loved the pairing of something smoky with red meat. But I don’t have much more to say about it than that.</p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5189.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
<center>Venison with smoked carrots.</center>
</p>

<p>Now came the desserts, of which there were many. Surprisingly, I liked the first one: grapes with grape ice. It was very refreshing after the entire meal. The yogurt dessert was totally carried by the lemon-flavored shard of something that they put on top. It was definitely not carried by what I consider to be the blandest blueberries to ever exist. The beet candy and jelly were a neat idea but entirely forgettable. The dark chocolate was, as expected, extremely rich and heavenly. What I learned is that dark chocolate does not need to be bitter: it can carry the earthy taste without bitterness if it is treated correctly. There was one more dessert that was like a cheesecake topped with blueberries, but at this point I was tired of desserts (and giant, flavorless blueberries).</p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5191.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
 <img src="/~smalladi/assets/equitable/IMG_5192.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
<br />
<center>Grape with grape ice (left) and yogurt with blueberry topped with a lemon-flavored shard (right).</center>
</p>

<p>
<img src="/~smalladi/assets/equitable/IMG_5195.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
<img src="/~smalladi/assets/equitable/IMG_5196.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 40%;" />
<br />
<center>Beet jelly and beet candy (left) and handmade dark chocolate (right)</center>
</p>

<h1 id="conclusion">Conclusion</h1>
<p>I don’t think it compares to American fine-dining. There were some highlights and some lowlights, but overall the first few courses read like a restaurant trying too hard and failing to put something meaningful on the plate. The more substantial dishes were good but not unique – I could have gotten them at a mid-tier Italian restaurant. I do think part of the problem is that I didn’t understand a lot of what they were saying was on the plate, and at a certain point, I just treated it like a fun mystery. But maybe I would have liked it more if I had sought out the flavors they intended to present.</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>To be fair, the Alps does produce some of the greatest water in the world. All of the water in Switzerland is drinkable unless noted otherwise, and I’ve even filled up my water bottle from a stone decorative fountain! <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction I’ve been in Europe for around two and a half weeks but barely had the chance to dictate my own food choices. The first week was spent at a conference that provided all of the meals (cafeteria-style but still pretty good), and the last week was spent on a deadline, so I just ate the food I packed for the trip. I went to Whole Foods before I left and got many varieties of cup noodles, fully cooked curries, and rice. These are actually pretty good in flavor and kept well in the suitcase!]]></summary></entry><entry><title type="html">Le CouCou</title><link href="cs.princeton.edu/~smalladi/blog/2022/08/17/lecoucou/" rel="alternate" type="text/html" title="Le CouCou" /><published>2022-08-17T00:00:00-07:00</published><updated>2022-08-17T00:00:00-07:00</updated><id>cs.princeton.edu/~smalladi/blog/2022/08/17/lecoucou</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2022/08/17/lecoucou/"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>I really knew nothing about this place before going in. I had nothing to do with picking it, but I really, really enjoyed it! Generally French cuisine seems like an absurd overload of butter in an attempt to approach umami, but this was really unique and memorable. I had no issues with my gluten allergy here, and the waiter was very helpful in steering us away from a fixed menu experience. Although they can adapt the fixed menu to be gluten-free, he said the experience was severely compromised and it’s better to go a la carte.</p>

<p>Overall the pictures are really bad quality for this post because I sat right under a light. But it’s ok.</p>

<p>
<img src="/~smalladi/assets/le_coucou/IMG_4830.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 50%;" />
<br />
<center>The waiter: don't get the Very Coucou Dinner.</center>
</p>

<h1 id="food">Food</h1>
<p>We started with the yellowfin tuna appetizer, which was actually sweet because of the raisins! I loved it though I forgot to take a picture. We then moved on to the pike dumpling with lobster sauce. To be honest, I was excited to eat a gluten-free dumpling, but this dumpling was nothing like what I expected. It was very soft (probably did not have an actual dough shell) and very large. The seafood flavor was really overwhelming (not surprising, I know), but the lobster sauce really calmed things down as a nice base.</p>

<p>
<img src="/~smalladi/assets/le_coucou/IMG_4831.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 50%;" />
<br />
<center>Pike dumpling in lobster sauce.</center>
</p>

<p>The main entree was a real hit. Loyal followers will remember that I was disappointed by the duck in Hutong. But the duck in Le Coucou (the dish it is well-known for) is fantastic. It came in two parts: the breast was already evenly divided between the two of us and accompanied by foie gras and cherries. But the rest of the duck was still on the bone<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> and was delivered in a pan for us to share. The duck had a great tart flavor from the cherries that cut through the fattiness, and the foie gras was such a nice treat to enjoy in between. I initially thought that all together, the dish would be far too rich, but it ended up being very balanced and delicious!</p>

<p>
<img src="/~smalladi/assets/le_coucou/IMG_4832.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 45%;" />
<img src="/~smalladi/assets/le_coucou/IMG_4833.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 45%;" />
<br />
<center>Individual portion of duck breast (left) and shared portion with foie gras (right).</center>
</p>

<p>We got two desserts. One was a pavlova: meringue with fruit and mint. It was a really nice way to clear the palate after such a rich main dish. The other was on the house: an assortments of chocolates and sweets, all of which were gluten-free!</p>

<h1 id="conclusion">Conclusion</h1>
<p>I would definitely come back here. I would probably get the same dishes though – I don’t think the menu was overflowing with gluten-free options. I don’t mind a restricted meal that’s this good!</p>

<hr />
<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>I let my dinner companion deal with this but it actually was not hard to get the meat off the bone since it was cooked so well! <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction I really knew nothing about this place before going in. I had nothing to do with picking it, but I really, really enjoyed it! Generally French cuisine seems like an absurd overload of butter in an attempt to approach umami, but this was really unique and memorable. I had no issues with my gluten allergy here, and the waiter was very helpful in steering us away from a fixed menu experience. Although they can adapt the fixed menu to be gluten-free, he said the experience was severely compromised and it’s better to go a la carte.]]></summary></entry><entry><title type="html">Veda</title><link href="cs.princeton.edu/~smalladi/blog/2022/04/08/veda/" rel="alternate" type="text/html" title="Veda" /><published>2022-04-08T00:00:00-07:00</published><updated>2022-04-08T00:00:00-07:00</updated><id>cs.princeton.edu/~smalladi/blog/2022/04/08/veda</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2022/04/08/veda/"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>This was a very spontaneous trip to Philadelphia, and since we left Princeton in the early afternoon, we were able to see the Rodin Museum! It was amazing to see so many of his most influential works up close, and it was a peaceful visit even though the museum is in the heart of the city.</p>

<p>I haven’t been able to eat Indian food at a restaurant in so long. Even though it’s one of the most GF-friendly cuisines, many restaurants are not educated on what gluten is and hence can cross-contaminate. It’s not terrible for me, because I can cook a lot of Indian dishes at home, but there are certainly some dishes that are just too time-consuming to be worth it.</p>

<p>We booked Veda last minute and found a slot only for 5pm, which was ok since we wanted to head back to Princeton relatively early in case there was severe traffic. Parking around the restaurant was easy to find but expensive.</p>

<h1 id="appetizers">Appetizers</h1>
<p>I miss chaat a lot. Pani puri, dahi puri, etc will always be out of reach, since it’s difficult to make these dishes without the factory-manufactured handheld wheat puris. But, other, more deconstructed forms of chaat like bhel puri are still possible. At Veda, I tried spinach chaat (which seemed to have an approximation of spinach pakoras in it?) and ragda patties. It was great to have the classic chaat flavors again: tamarind, onion, tomato, etc.</p>

<p>
<img src="/~smalladi/assets/veda/IMG_4179.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 45%;" />
 <img src="/~smalladi/assets/veda/IMG_4180.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 45%;" />
<br />
<center>Ragda patties (left) and spinach chaat (right)</center>
</p>

<p>Although the restaurant seems to be fancy (fancy enough to mark gluten-free items, at least), they didn’t deviate too far from the traditional chaat flavors and components. I found both dishes to be very comforting and to take me back to the small chaat restaurants I used to go to as a kid (in CA, not in India). The spinach chaat was a little inventive, but it didn’t feel too far from the taste of mixed vegetable pakoras, where the occasional leaves soak up the oil during deep frying.</p>

<h1 id="main-dishes">Main Dishes</h1>
<p>We ordered malai kofta and tandoori chicken for the main dishes.</p>

<p>
<img src="/~smalladi/assets/veda/IMG_4183.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 35%;" />
 <img src="/~smalladi/assets/veda/IMG_4184.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 55%;" />
<br />
<center>Malai kofta (left) and tandoori chicken (right)</center>
</p>

<p>Malai kofta is notoriously difficult to make at home<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup>, and it’s my favorite North Indian dish, so it was the obvious choice. We got it with a spice rating of 4 out of 5, which ended up being right for me but too much for weaker souls.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> The gravy was good, but the koftas didn’t have as much flavor in them as I would have wanted. In theory, a good gravy can compensate for a blander kofta, but in implementation, this doesn’t work out so well.</p>

<p>The tandoori chicken was pretty dry, as is customary. I never ate this much growing up, since I was vegetarian. It felt a bit weird to have meat with Indian flavors and chutneys, and I wasn’t really able to get past that. The mint chutney did taste really good with the tandoori char. It made me wonder: if the restaurant had mint chutney, why not put it on the chaat too?</p>

<h1 id="desserts">Desserts</h1>
<p>We tried the mango lassi, which was delicious but required my mouth to act as the world’s most powerful vacuum in order for me to drink through the straw. We also ordered kheer and shrikhand (the two exciting GF dessert options).</p>

<p>
<img src="/~smalladi/assets/veda/IMG_4187.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 75%;" />
<center>Kheer (bottom) and shrikhand (top)</center>
</p>

<p>I didn’t really eat these desserts as a kid because I was a gulab jamun girl, but I was still excited to try them out. The shrikhand was mixed with white chocolate and had some raspberry taste (though I didn’t see any raspberries?), which was pretty modern. They also gave a lot of it, considering how thick the dessert is. It was absolutely delicious, and getting the little, easily melted pieces of white chocolate in my bite made me happy.</p>

<p>The kheer was a little disappointing. The rice seemed undercooked, and the “pudding” didn’t really come together. It was like slightly undercooked rice swimming in a vaguely sweet liquid. If not for the texture issues, it could have been better than the shrikhand, since it wasn’t so overwhelmingly sweet.</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>Even in its most basic form, it requires par-boiling potatoes and grating them with paneer (which is so hard to grate) to form the koftas. Generally adding more vegetables gives the kofta more flavor. If you have the wrong amount of moisture, the dumplings fall apart during frying, which is really disappointing after all of that work. Even if you succeed, you still have to make the gravy afterwards… <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>This inspired an order of raita, which was pretty good but needed more cucumbers or tomatoes in my opinion. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction This was a very spontaneous trip to Philadelphia, and since we left Princeton in the early afternoon, we were able to see the Rodin Museum! It was amazing to see so many of his most influential works up close, and it was a peaceful visit even though the museum is in the heart of the city.]]></summary></entry><entry><title type="html">Hutong</title><link href="cs.princeton.edu/~smalladi/blog/2022/03/16/hutong/" rel="alternate" type="text/html" title="Hutong" /><published>2022-03-16T00:00:00-07:00</published><updated>2022-03-16T00:00:00-07:00</updated><id>cs.princeton.edu/~smalladi/blog/2022/03/16/hutong</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2022/03/16/hutong/"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>People around me are always talking about going to Edison, NJ for authentic Indian and Chinese food. I didn’t have much of a chance to do this pilgrimage before I was diagnosed as gluten-free, and these restaurants rarely mark anything as gluten free.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> Usually, I am okay with this, since I can replicate most dishes on my own, but lately I have wanted to try some Chinese dishes that are hard to cook in a household. Chief among these was Peking duck.</p>

<p>Peking duck faded to the back of my mind until one of my friends mentioned that he had eaten a delicious Peking duck in NYC at a fancy restaurant. Fancy restaurant usually implies awareness of celiac disease, so we called them and discovered they can make the Peking duck gluten-free (sort of, but more on that later). Hence we planned a trip to Hutong.</p>

<p>Everything here was safe to eat and didn’t upset my stomach.</p>

<h1 id="other-items">Other Items</h1>
<p>Hutong has food besides the Peking duck, and we did order a lot of other starters and sides.</p>

<p>
<img src="/~smalladi/assets/hutong/IMG_4077.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 25%;" />
 <img src="/~smalladi/assets/hutong/IMG_4078.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 35%;" />
 <img src="/~smalladi/assets/hutong/IMG_4079.JPG" alt="legend" style="
 margin-left: auto;
 margin-right: auto;
 width: 35%;" />
<br />
<center>From left to right: Comfortably Numb, Chilled Green Asparagus, and Ma La Chilli Prawns </center>
</p>

<p>The cocktails were generally lighter on alcohol and didn’t particularly stick out as unique concoctions. The asparagus was delicious, though it had so few ingredients and was so simple that I couldn’t help but think I could have made it at home for a fraction of the cost.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" class="footnote" rel="footnote">2</a></sup> The prawns were the highlight of the whole meal for me. They were so crispy and flavorful: the classic deep-fried grease hit at the same time as the spice with perfect balance. The batter wasn’t as light as rice flour or as heavy as chickpea flour, so I was convinced there was flour in the breading (which was <strong>not true</strong>)! I don’t really get the trend of Chinese food putting a bunch of peppers on the plate that shouldn’t be eaten. I ate one of these and kind of regretted it.</p>

<p>The pictures are just a sampling of what we ordered, since we had a large group. We also tried the duck fried rice, which had a disappointingly low ratio of meat to rice, and others at the table ordered some gluten-filled dim sum items.</p>

<h1 id="peking-duck">Peking Duck</h1>
<p>The duck arrives in two phases: the first is the desirable parts of the duck cooked on their own, and the second is the less desirable parts minced up and stir fried with green beans and some sauce. This was where the first disappointment hit: the second phase is not gluten-free and they pre-mix the sauce so it’s impossible to make gluten-free. This was surprising to me: on the phone they seemed to suggest that the gluten-free Peking duck experience would not be compromised at all (which would make sense, since the duck is just cooked in a special way and served with some simple sides). Also, what kind of fancy restaurant can’t re-mix a sauce? But we went all the way to New York so I acted like it didn’t matter.</p>

<p>
<img src="/~smalladi/assets/hutong/IMG_4081.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 75%;" />
<center>Phase 1 of the Peking duck</center>
</p>

<p>When they put it on the table, the duck looked pretty exciting. It was a little alarming that they gave this for 3 people and I could only eat this phase, but luckily others at the table were nice and let me have more than my fair share. Once again, the waiter delivered some disappointing news: I couldn’t have any of the sides or the pancakes with the duck, not even the hoisin sauce<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" class="footnote" rel="footnote">3</a></sup>. They provided me some sad lettuce pieces that I could use to wrap the duck myself and gave honey on the side.</p>

<p>
<img src="/~smalladi/assets/hutong/IMG_4084.JPG" alt="legend" style="display:block;
 margin-left: auto;
 margin-right: auto;
 width: 50%;" />
<center>Traditional but gluten-ed way of enjoying Peking duck</center>
</p>

<p>Unsurprisingly, the little green veggie sticks and the hoisin sauce are crucial to the Peking duck experience. Without them, there’s no balance to the rich, fatty duck. I was only able to eat a few pieces before I felt it was too greasy. I tried to eat the coveted crispy skin with the provided honey, and it was just too decadent to enjoy.</p>

<p>For what it’s worth, the second phase of the duck looked pretty lame. Everyone at the table said it was not as good as the first phase (which they might have said just to make me feel better). Overall, it seems that the gluten-free Peking duck experience was a bit of a letdown…time to find another place!</p>

<hr />

<div class="footnotes" role="doc-endnotes">
  <ol>
    <li id="fn:1" role="doc-endnote">
      <p>It’s worth noting that most Indian food is gluten-free except for the ingredient <a href="https://www.npr.org/sections/thesalt/2016/06/22/482779599/meet-hing-the-secret-weapon-spice-of-indian-cuisine">asafoetida, also known as hing</a>. And this spice does not contain gluten on its own, but it is usually processed with a bit of flour to make it easier to grind up. Hing is not ubiquitous in Indian cuisine, but I still worry about cross-contamination. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:2" role="doc-endnote">
      <p>Sadly I have this thought a lot. <a href="#fnref:2" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
    <li id="fn:3" role="doc-endnote">
      <p>Ok, maybe this is not very surprising, but I assumed when they said they had a gluten-free offering of the duck, they had gluten-free hoisin sauce. It’s fairly common and easy to find. <a href="#fnref:3" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
    </li>
  </ol>
</div>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction People around me are always talking about going to Edison, NJ for authentic Indian and Chinese food. I didn’t have much of a chance to do this pilgrimage before I was diagnosed as gluten-free, and these restaurants rarely mark anything as gluten free.1 Usually, I am okay with this, since I can replicate most dishes on my own, but lately I have wanted to try some Chinese dishes that are hard to cook in a household. Chief among these was Peking duck. It’s worth noting that most Indian food is gluten-free except for the ingredient asafoetida, also known as hing. And this spice does not contain gluten on its own, but it is usually processed with a bit of flour to make it easier to grind up. Hing is not ubiquitous in Indian cuisine, but I still worry about cross-contamination. &#8617;]]></summary></entry><entry><title type="html">Marea</title><link href="cs.princeton.edu/~smalladi/blog/2022/03/07/marea/" rel="alternate" type="text/html" title="Marea" /><published>2022-03-07T00:00:00-08:00</published><updated>2022-03-07T00:00:00-08:00</updated><id>cs.princeton.edu/~smalladi/blog/2022/03/07/marea</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2022/03/07/marea/"><![CDATA[<h1 id="introduction">Introduction</h1>
<p>We went to Marea to celebrate my birthday a few days late. We spent only part of the day in New York and had high tea just before going to the restaurant. It turns out that high tea actually involves a lot of food, so this might have hampered our enjoyment of the food (as opposed to if we had gone on empty stomachs). Regardless, we thoroughly enjoyed everything we did eat at Marea.</p>

<p>It had started raining, so we decided to get to the restaurant earlier and grab a drink at the bar if we needed to wait for our reservation. We arrived slightly before 5pm for a 5:45pm reservation, but the staff were very accommodating and sat us as soon as the restaurant team meeting was over. In the few minutes we spent at the bar, we checked the <a href="https://www.nytimes.com/2009/10/21/dining/reviews/21rest.html">New York Times review</a> of the restaurant for suggestions on what to order. The basic gist we had was that appetizers and pasta were good, but the fish-centric second course dishes were not. This was OK with us at the time, because we weren’t especially hungry.</p>

<p><img src="/~smalladi/assets/marea/IMG_3941.jpeg" alt="legend" style="display: block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<h1 id="service">Service</h1>
<p>Before even talking about the food, I have to mention the service. Our waitress (whose name I regrettably didn’t get) was incredibly attentive and thoughtful without hovering over us. She had great recommendations and went above and beyond to ensure all of the food coming to our table was gluten-free. We also appreciated the other service members of the restaurant, especially that someone came by and re-folded our napkins when we got up to go to the restrooms.</p>

<h1 id="bread-and-amuse-bouche">Bread and Amuse-Bouche</h1>
<p><img src="/~smalladi/assets/marea/IMG_3944.jpeg" alt="legend" style="  margin-left: auto;  margin-right: auto;  width:49%;" />
<img src="/~smalladi/assets/marea/IMG_3947.jpeg" alt="legend" style="  margin-left: auto;  margin-right: auto;  width: 49%;" /></p>

<p>The free offerings of a restaurant speak volumes. The gluten-free bread here was not exciting. It was cracker-like in texture and had some weird seeds stuck to the crust as is common practice. I never understood the seeds on the side of the bread: like, does it mean there are seeds in the bread? Is it some kind of healthiness indicator? The dipping options shined here. They provided olive oil and an incredible eggplant mousse-like spread with it. It was quite surprising to get something eggplant-forward at a seafood restaurant, but the rest of the meal also heavily featured eggplant (in part because of our item selections).</p>

<p><img src="/~smalladi/assets/marea/IMG_3949.jpeg" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<p>The amuse bouche was a twist on a caprese salad, and it also featured eggplant. To be honest, it didn’t particularly arouse my taste buds. It also didn’t convey a clear vision for what our meal would look like or what flavors would be highlighted (except for eggplant, which tasted wildly different each time we ate it). A great bite, but not one that lingered and excited the mind.</p>

<h1 id="crudi-and-starter">Crudi and Starter</h1>
<p><img src="/~smalladi/assets/marea/IMG_3950.jpeg" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<p>We were excited about a few different crudo options, so we got the “Assagio de Tre,” which read like the chef would select three exciting crudi for us, but actually just meant we had to pick the three we wanted samples of. We got the hamachi, tonno, and cannolicche (without the gluten-containing fried ingredients). I didn’t enjoy the cannolicche as much as the other two, but that may have been because of a general aversion to clam texture. The hamachi was by far the best bite in terms of composition: the bite traveled smoothly from the gentle fish flavor to the citrus from the kumquat. The raw tuna was most satisfying as far as the fish quality was concerned, but I’m not sure if that’s just because it was cut in a shape that made the bite feel more substantial (and maybe closer to what I’m used to from raw fish). Overall, I think the crudi was worth it but didn’t seem to convey a distinctly Italian theme.</p>

<p><img src="/~smalladi/assets/marea/IMG_3953.jpeg" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<p>We got the Astice, an intriguing combination of eggplant, cheese, and lobster, on the recommendation of the New York Times article. I’m very new to lobster (and seafood in general), but this dish educated me on the appeal of lobster. Interestingly, the eggplant strips and the tomatoes served the same purpose: bursts of acidity amid a creamy umami experience. The burrata was probably whipped and wrapped nicely around the hunks of lobster while adding to the texture of each bite.</p>

<h1 id="main-dish">Main Dish</h1>
<p><img src="/~smalladi/assets/marea/IMG_3954.jpeg" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<p>We got the gluten-free pasta with red wine braised octopus and bone marrow. Our waitress suggested that was the most popular dish the restaurant was known for. I found the octopus delicious and tender, and the bone marrow pieces lended a pop of richness to the dish. Unlike most pasta-plus-something dishes, the entire item was cohesive, and it felt like each ingredient needed the others. The sauce adequately coated the pasta without pooling into the bottom of the bowl, and the chew of the octopus benefited from the melting bone marrow texture.</p>

<p>The gluten-free pasta was incredible. I recently started making my own (overly thick) gluten-free noodles at home, so I’m no longer satisfied with the standard gluten-free pastas that disintegrate in sauces. It was clear the restaurant put effort into making this pasta, and the ridges and shape held steadfast amid slippery conditions.</p>

<h1 id="desserts">Desserts</h1>
<p><img src="/~smalladi/assets/marea/IMG_3957.jpeg" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<p>We immediately ordered the tiramisu (and our waitress knew we would leap at the option of gluten-free tiramisu). But, we actually also received a tropical sorbet because we were celebrating my birthday. The sorbet may have been more exciting if I hadn’t just eaten three giant scoops of sorbet at high tea. Anyways, I appreciated the thought and design.</p>

<p><img src="/~smalladi/assets/marea/IMG_5856.JPG" alt="legend" style="display:block;  margin-left: auto;  margin-right: auto;  width: 50%;" /></p>

<p>The tiramisu came through a stunning presentation. The cube, dusted in cocoa flours on five of its sides, was very unique. It came with some cream and cookie-esque crumbles, but the cake itself was the star. The cream and the cake were the same texture, and my fork glided through the cross-section just under the force of its weight. The flavors were strong and evenly distributed through the layers, and it was simply the best tiramisu I’ve ever had, gluten-free or not.  There were no twists on the dessert: it was just the classic item executed perfectly.</p>

<h1 id="drinks">Drinks</h1>
<p>On top of this fantastic dessert, our waitress and the restaurant’s bartender worked together to make me a dessert cocktail. We requested something with Bailey’s in it but without coffee, and the bartender whipped something up that was unique, tasty, and perfectly matched the tiramisu’s flavor profile.</p>

<p>During the main meal, I got the navy punch cocktail, which purportedly contained “clarified milk.” I was nervous about it but reassured by my waitress, and indeed, the cocktail was clear and did not actually have milk in it. It had a creaminess that was reminiscent of cream soda. Our waitress told us the cocktail takes 4 days to create, and I fully believe it, given the flavor profiles developed.</p>

<h1 id="summary">Summary</h1>
<p>Our meal at Marea was delicious, though it was hard to grasp the culinary theme or vision from the dishes we got. Most items alone were fantastic, and the use of eggplant was innovative and thought-provoking. We followed the NYT suggestion and stayed away from any courses after the Primi section of the menu. The service, including the accommodations for celiac disease, was amazing and elevated the experience. If I returned, I would order many of the same dishes and try another pasta, since that gluten-free pasta did not let down my expectations.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Introduction We went to Marea to celebrate my birthday a few days late. We spent only part of the day in New York and had high tea just before going to the restaurant. It turns out that high tea actually involves a lot of food, so this might have hampered our enjoyment of the food (as opposed to if we had gone on empty stomachs). Regardless, we thoroughly enjoyed everything we did eat at Marea.]]></summary></entry><entry><title type="html">Infinite Winter - Stage 2</title><link href="cs.princeton.edu/~smalladi/blog/2020/12/26/infinite-jest-2/" rel="alternate" type="text/html" title="Infinite Winter - Stage 2" /><published>2020-12-26T00:00:00-08:00</published><updated>2020-12-26T00:00:00-08:00</updated><id>cs.princeton.edu/~smalladi/blog/2020/12/26/infinite-jest-2</id><content type="html" xml:base="cs.princeton.edu/~smalladi/blog/2020/12/26/infinite-jest-2/"><![CDATA[<h1 id="the-second-stretch">The Second Stretch</h1>

<p>I see why Infinite Summer chose this pacing for the book. The second stretch took a lot longer than was scheduled because we added a new member to our book club (yay!). Some of my thoughts below were synthesized in conversation with them. I think this made me pause to reflect much more on what I’m getting out of this book. Although some pages can be quite difficult to read (either for their winding style or for their heavy emotional content), I ultimately didn’t want to put this book down. Which is sometimes not even true of books that are clearer in their writing style.</p>

<p>What follows are my observations until p. 168 of the book (17%). Also, the pacing is starting to break down, because it doesn’t seem like these markers align across the physical and digital versions of this book. In fact, it doesn’t even align across different Kindle versions!</p>

<h1 id="family">Family</h1>

<p>Undoubtedly we are meant to see Hal’s condition from many different perspectives: the global political state (discussed below), his family, the city around him, his peers, etc. In this stage, I found the discussion of his family particularly interesting. We had a glimpse of the odd relationship he may have with Uncle Charles (C.T.) in the opening scenes of the book, where Hal’s uncle vehemently defends his behavior at the University of Arizona interview. The other clear indication I had that family may be a central theme in this novel is this passage from the first stage (when Hal is speaking with a “therapist,” who ends up being his father in disguise):</p>

<blockquote>
  <p>I’m <em>ten</em> for Pete’s sake. I think maybe your appointment calendar’s squares got juggled. I’m the potentially gifted ten-year-old tennis and lexical prodigy whose mom’s a continental mover and shaker in the prescriptive grammar academic world and whose dad’s a towering figure in optical and avant-garde film circles and single-handedly founded the Enfield Tennis Academy but drinks Wild Turkey at like 5:00 a.m. and pitches over sideways during dawn drills, on the courts, some days, and some days presents with delusions about people’s mouths moving but nothing coming out.</p>
</blockquote>

<h2 id="siblings">Siblings</h2>

<p>We’re introduced to Hal’s siblings, Mario and Orin. I love the way that these characters are set up for an easy compare-and-contrast analysis. Mario is much less intellectually inclined than Hal, and at first, I felt bad for him. Many people take advantage of him because he seems to be gullible. But, when we see Mario with Gerhardt Schtitt (the head coach at the tennis academy), I realized what Mario brings to the table. Their fun friendship is endearing, because Mario listens to Schtitt and is a rare emotional outlet for him. Even though Mario doesn’t bring the traditional currency of utility (athleticism) to the tennis academy, he is a fixture around the school.</p>

<p>Orin is more unsettling. The way he speaks with Hal is cryptic and loaded, telling him “[his] head is filled with things to say.” I didn’t know what to make of this in the first stage of reading, but now we get more of Orin’s story. He seems to have an odd relationship with Avril, his mother, that is simultaneously obsessive and terrifying. He seems to be connected to this entire Canadian separatist storyline, which also includes Avril.</p>

<p>Hal’s relationships with his two oddball brothers is especially interesting. He is tolerant and patient with Mario, showcasing a more tender side than I would have expected. Orin is his older brother, and his apparent inability to cope with life despite being a professional athlete (presumably the goal of many tennis academy students) is probably sobering to Hal. It’s also worth noting that there is probably some tension between Mario and Orin, because when Hal is talking to Orin, he tells Mario that he wouldn’t know who’s on the other end of the line.</p>

<h2 id="parents">Parents</h2>

<p>We get more of a glimpse into Avril’s life in this stage. First of all, one connection I made only while writing this blog post is that Avril likely had an affair with the medical attaché that we met. She was quite influential in the academic world, but due to her separatist ties developed in graduate school, she couldn’t get a visa into the United States. She has a child (Orin) with James (Hal’s dad) to get around this. My interest in her character is particularly piqued, but we don’t get much else.</p>

<p>Instead, we get a deeper portrait of James. His father was a competitive junior tennis player (what’s with everyone being competitive junior players but not professional ones? It’s almost as though these are two different sports) and an actor. James similarly was good at tennis and also studied optical physics. He was also an artist, making bleeding-edge films. I couldn’t quite understand whether he was good or bad at filmmaking. How do we get from this rather sober and flattering depiction of James to the version that disguised himself as a therapist to get some secrets out of Hal?</p>

<p>We also see a weird scene with James and his father, James Sr., which I also discuss more below. James Sr. is trying to get James to focus more on playing tennis, and he reminisces on his father (Mario Sr.) and his apparent disappointment in James Sr., who suffered a knee injury and couldn’t play anymore. The cyclical nature of their names and the recurring themes of prodigal talent and pressure are apparent in this conversation.</p>

<h1 id="politics">Politics</h1>

<p>Perhaps this is the biggest mystery driving continued interest in the novel. What happened to Canada? What are the separatists in favor of separating from? The acronyms defining the political landscape of this novel are truly infinite (haha) in number. There is the Organization of North American Nations (O.N.A.N.), which seems to be the main conglomeration of nations that we care about.</p>

<p>We start with Rémy Marathe, a member of Assassins Fateuils Rolents (A.F.R.). First of all, I’m surprised the idea of wheelchair assassins hasn’t been picked up for some kind of movie, because I think that would be very cool and fun to watch. Rémy is a triple (maybe quadruple?) agent between the A.F.R. and the Office of Unspecified Services (O.U.S.), which seems to be the traditional government structures we know (C.I.A., Secret Service, etc). He was supposed to pretend to betray the A.F.R. (i.e., triple agent), but now he seems to be sharing real information (i.e., quadruple agent). His true loyalty is ambiguous, but his motivation is clear: he wants medical care for his wife. In some ways, the effort he has to go through to get this care reminds me of the convoluted American healthcare system.</p>

<p>We are introduced to Rémy in his meeting with Hugh Steeply, who works for the O.U.S. I’m not sure what to make of his cross-dressing disguise as journalist Helen Steeply…in the one scene we saw so far, it doesn’t appear that he is genderqueer, but who knows what is to come. Given the later reference to blackface, the charitable reading is that his character is a satire on disguise, and the less generous one is that DFW was wildly politically incorrect. Disguise aside, Hugh seems pretty simple, he doesn’t have any bouncing affiliations.</p>

<p>From their conversation, we are to see a connection to Hal and his family. In particular, the Entertainment that they are discussing seems to have been made by James (because they rumor that the filmmaker’s promiscuous wife was originally from Quebec).</p>

<h1 id="the-surreal-and-the-mundane">The Surreal and the Mundane</h1>

<p>The juxtaposition of the surreal and the mundane was very striking to me. Amid the slow reveal of an apparent political plot with various colorful players, we are treated to mundane scenes reminiscent of a bildungsroman: commiseration in the locker room, the fumblings of young love, brothers teasing each other. These are interspersed with surreal and absurdist images: the guru on top of the water cooler, Rémy and Hugh’s meeting in the desert, Orin’s neurotic visions and tendencies.</p>

<p>Perhaps where this was strongest was the conversation between James and James Sr. (i.e., between Hal’s father and grandfather). What begins as a rather innocuous setting where James Sr. wants to take James to play tennis spirals into a pages-long monologue on James Sr.’s life.</p>

<h1 id="favorite-quotes">Favorite Quotes</h1>

<blockquote>
  <p>One of the positives to being visibly damaged is that people can sometimes forget you’re there, even when they’re interfacing with you. You almost get to eavesdrop. It’s almost like they’re like: If nobody’s really in there, there’s nothing to be shy about.</p>
</blockquote>

<h2 id="tennis">Tennis</h2>

<blockquote>
  <p>continuum of infinities of possible move and response, Cantorian and beautiful because infoliating, contained, this diagnate infinity of infinities of choice and execution, mathematically uncontrolled but humanly contained, bounded by the talent and imagination of self and opponent, bent in on itself by the containing boundaries of skill and imagination that brought one player finally down, that kept both from winning, that made it, finally, a game, these boundaries of self.</p>
</blockquote>

<blockquote>
  <p>By learning, in palestra, the virtues that pay off directly in competitive games, the well-disciplined boy begins assembling the more abstract, gratification-delaying skills necessary for being a ‘team player’ in a larger arena: the even more subtly diffracted moral chaos of full-service citizenship in a State.</p>
</blockquote>

<blockquote>
  <p>The true opponent, the enfolding boundary, is the player himself. Always and only the self out there, on court, to be met, fought, brought to the table to hammer out terms. The competing boy on the net’s other side: he is not the foe: he is more the partner in the dance. He is the what is the word excuse or occasion for meeting the self. As you are his occasion. Tennis’s beauty’s infinite roots are self-competitive. You compete with your own limits to transcend the self in imagination and execution. Disappear inside the game: break through limits: transcend: improve: win. Which is why tennis is an essentially tragic enterprise, to improve and grow as a serious junior, with ambitions. You seek to vanquish and transcend the limited self whose limits make the game possible in the first place. It is tragic and sad and chaotic and lovely. All life is the same, as citizens of the human State: the animating limits are within, to be killed and mourned, over and over again.</p>
</blockquote>

<h2 id="miscellaneous">Miscellaneous</h2>

<blockquote>
  <p>‘What if sometimes there is no choice about what to love? What if the temple comes to Mohammed? What if you just love?without deciding? You just do: you see her and in that instant are lost to sober account-keeping and cannot choose but to love?’</p>
</blockquote>

<blockquote>
  <p>He’s like a baby. Everything he sees hits him and sinks without bubbles. He just sits there. I want to be like that. Able to just sit all quiet and pull life toward me, one forehead at a time.</p>
</blockquote>

<blockquote>
  <p>Good old traditional audio-only phone conversations allowed you to presume that the person on the other end was paying complete attention to you while also permitting you not to have to pay anything even close to complete attention to her.</p>
</blockquote>

<blockquote>
  <p>But that’s not the way I… that’s not the way a real player plays. With respect and due effort and care for every point. You want to be great, near-great, you give every ball everything. And then some. You concede nothing. Even against loxes. You play right up to your limit and then pass your limit and look back at your former limit and wave a hankie at it, embarking.</p>
</blockquote>]]></content><author><name></name></author><summary type="html"><![CDATA[The Second Stretch]]></summary></entry></feed>